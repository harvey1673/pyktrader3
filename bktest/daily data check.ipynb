{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['PY3_PROD'] = '1'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.system('kinit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List\n",
    "import datetime\n",
    "from pycmqlib3.utility import misc\n",
    "\n",
    "from pycmqlib3.utility.dbaccess import *\n",
    "from pycmqlib3.utility import dataseries\n",
    "from pycmqlib3.analytics.tstool import *\n",
    "from pycmqlib3.analytics.btmetrics import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "#pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_contract_list_table(datetime.date(2023,1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load eod mark from exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_scripts.aks_data_update import update_hist_fut_daily\n",
    "\n",
    "update_hist_fut_daily(start_date=datetime.date(2022,12,22),\n",
    "                          end_date=datetime.date(2023,1,6),\n",
    "                          exchanges=['GFEX'],\n",
    "                          flavor='mysql',\n",
    "                          fut_table='fut_daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check factor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list = ['rb', 'hc', 'i', 'j', 'jm']\n",
    "roll_label = 'CAL_30b'\n",
    "freq = 's1'\n",
    "db_table = 'fut_fact_data'\n",
    "fact_list = [\"ryield_1_nmb_120\", \"basmom_100_nma_120\", \"basmom_170_nma_120\",\n",
    "            \"ryield_1_nma_20\", \"ryield_1_nma_110\"]\n",
    "start_date = datetime.date(2022,10,1)\n",
    "end_date = datetime.date(2022,12,30)\n",
    "df = load_factor_data(prod_list, \n",
    "                      factor_list = fact_list,\n",
    "                      roll_label = roll_label,\n",
    "                      start = start_date,\n",
    "                      end = end_date,\n",
    "                      freq = freq,\n",
    "                      db_table = db_table)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import json\n",
    "from pycmqlib3.utility.misc import day_shift, CHN_Holidays, sign, is_workday, inst2product\n",
    "import pycmqlib3.analytics.data_handler as dh\n",
    "from misc_scripts.factor_data_update import update_factor_data, generate_daily_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_all = [\n",
    "    ('tscarry', 'ryieldnmb', 2.8, 1, 120, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "\n",
    "    ('tscarry', 'ryieldnmb', 1.0, 1, 122, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'ryieldqtl', 0.8, 1, 20, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'ryieldqtl', 0.8, 1, 60, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'ryieldqtl', 0.8, 1, 244, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "\n",
    "    ('tscarry', 'basmomnma', 0.7, 100, 120, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'basmomnma', 0.5, 170, 120, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    # ('tscarry', 'basmomnma', 0.2, 230, 120, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "\n",
    "    ('tscarry', 'basmomnma', 0.5, 20, 122, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'basmomnma', 0.42, 60, 122, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'basmomnma', 0.35, 120, 122, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'basmomnma', 0.35, 180, 122, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'basmomqtl', 2.0, 120, 20, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "    ('tscarry', 'basmomqtl', 1.8, 240, 20, 1, (None, {}, ''), [0.0, 0.0]),\n",
    "\n",
    "    ('xscarry', 'ryieldsma', 0.6, 1, 30, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    # ('xscarry', 'ryieldsma', 0.15, 1, 110, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'ryieldsma', 1.5, 1, 190, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'ryieldnma', 1.5, 1, 20, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'ryieldnma', 1.8, 1, 110, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    # ('xscarry', 'ryieldnma', 0.2, 1, 210, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "\n",
    "    ('xscarry-rank', 'ryieldnma', 1.4, 1, 20, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry-rank', 'ryieldnma', 1.4, 1, 122, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry-rank', 'ryieldnma', 1.4, 1, 244, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "\n",
    "    ('xscarry', 'basmomsma', 0.6, 100, 10, 5, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'basmomsma', 0.6, 220, 10, 5, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'basmomnma', 1.5, 80, 120, 5, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'basmomnma', 1.5, 150, 120, 5, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry', 'basmomnma', 1.5, 220, 120, 5, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "\n",
    "    ('xscarry-rank', 'basmomnma', 2.0, 20, 122, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry-rank', 'basmomnma', 2.0, 100, 122, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xscarry-rank', 'basmomnma', 2.0, 170, 122, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "\n",
    "    ('tsmom', 'hlbrk', 2.0, 10, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'hlbrk', 1.5, 30, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'hlbrk', 1.2, 240, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'momnma', 0.2, 10, 60, 1, (None, {}, ''), [0.0]),\n",
    "    ('tsmom', 'momnma', 0.07, 220, 60, 1, (None, {}, ''), [0.0]),\n",
    "    # ('tsmom', 'momxma', 0.2, 40, 30, 5, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('tsmom', 'momxma', 0.15, 40, 80, 5, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('tsmom', 'mixmom', 0.375, 10, 1, 10, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('tsmom', 'mixmom', 0.3, 30, 1, 10, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('tsmom', 'mixmom', 0.3, 220, 1, 10, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('tsmom', 'rsixea', 0.25, 30, 40, 5, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('tsmom', 'rsixea', 0.25, 30, 110, 5, (misc.sign, {}, 'sign'), [0.0]),\n",
    "    # ('xsmom', 'mom', 0.15, 160, 1, 5, (None, {}, ''), [0.0], 0.2),\n",
    "\n",
    "    ('tsmom', 'hlbrk', 0.5, 20, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'hlbrk', 0.5, 40, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'hlbrk', 0.5, 61, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'hlbrk', 0.5, 122, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'hlbrk', 0.5, 244, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('tsmom', 'macdnma', 0.22, 8, 160, 5, (dh.response_curve, {\"response\": \"reverting\", \"param\": 2}, 'reverting'),\n",
    "     [1.5, 10.0]),\n",
    "    ('tsmom', 'macdnma', 0.20, 16, 160, 5, (dh.response_curve, {\"response\": \"reverting\", \"param\": 2}, 'reverting'),\n",
    "     [1.5, 5.0]),\n",
    "    ('tsmom', 'macdnma', 0.18, 24, 160, 5, (dh.response_curve, {\"response\": \"reverting\", \"param\": 2}, 'reverting'),\n",
    "     [1.5, 3.34]),\n",
    "\n",
    "    ('xsmom', 'hlbrk', 1.2, 120, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom', 'hlbrk', 1.2, 240, 1, 10, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom', 'mom', 1.0, 20, 1, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom', 'mom', 1.0, 210, 1, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom', 'momnma', 1.0, 130, 90, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom', 'momnma', 1.0, 240, 90, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom', 'momsma', 0.8, 140, 120, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom', 'momsma', 0.8, 240, 120, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    # ('xsmom', 'rsiema', 0.1, 70, 60, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    # ('xsmom', 'rsiema', 0.1, 100, 80, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    # ('xsmom', 'rsiema', 0.1, 90, 10, 5, (None, {}, ''), [0.0], 0.2),\n",
    "    # ('xsmom', 'macdnma', 0.1, 8, 200, 5, (dh.response_curve, {\"response\": \"absorbing\", \"param\": 2}, \"absorbing\"), [1.5, 12.5], 0.2),\n",
    "    # ('xsmom', 'macdnma', 0.1, 16, 200, 5, (dh.response_curve, {\"response\": \"absorbing\", \"param\": 2}, \"absorbing\"), [1.5, 6.25], 0.2),\n",
    "    # ('xsmom', 'macdnma', 0.1, 32, 200, 5, (dh.response_curve, {\"response\": \"absorbing\", \"param\": 2}, \"absorbing\"), [1.5, 3.125], 0.2),\n",
    "    # ('xsmom', 'macdnma', 0.1, 64, 100, 5, (dh.response_curve, {\"response\": \"absorbing\", \"param\": 2}, \"absorbing\"), [1.5, 1.56], 0.2),\n",
    "\n",
    "    ('xsmom-rank', 'hlbrk', 0.375, 20, 1, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom-rank', 'hlbrk', 0.375, 40, 1, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom-rank', 'hlbrk', 0.375, 61, 1, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom-rank', 'hlbrk', 0.375, 122, 1, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom-rank', 'hlbrk', 0.375, 244, 1, 1, (None, {}, ''), [0.0, 0.0], 0.2),\n",
    "    ('xsmom-rank', 'momnma', 0.6, 10, 10, 1, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom-rank', 'momnma', 0.6, 130, 120, 1, (None, {}, ''), [0.0], 0.2),\n",
    "    ('xsmom-rank', 'momnma', 0.6, 240, 60, 1, (None, {}, ''), [0.0], 0.2),\n",
    "]\n",
    "\n",
    "\n",
    "commod_mkts = ['rb', 'hc', 'i', 'j', 'jm', 'ru', 'FG', 'cu', 'al', 'zn', 'pb', 'ni', 'sn', \\\n",
    "               'l', 'pp', 'v', 'TA', 'sc', 'm', 'RM', 'y', 'p', 'OI', 'a', 'c', 'CF', 'jd', \\\n",
    "               'AP', 'SM', 'SF', 'ss', 'CJ', 'UR', 'eb', 'eg', 'pg', 'T', 'PK', 'PF', 'lh', \\\n",
    "               'MA', 'SR', 'cs', 'TF', 'lu', 'fu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mkt = rb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\pyktrader3\\pycmqlib3\\utility\\dbaccess.py:76: SAWarning: Can't validate argument 'replace_string'; can't locate any SQLAlchemy dialect named 'replace'\n",
      "  conn.execute(table.table.insert(replace_string=\"\"), data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mkt = hc\n",
      "loading mkt = i\n",
      "loading mkt = j\n",
      "loading mkt = jm\n",
      "loading mkt = ru\n",
      "loading mkt = FG\n",
      "loading mkt = cu\n",
      "loading mkt = al\n",
      "loading mkt = zn\n",
      "loading mkt = pb\n",
      "loading mkt = ni\n",
      "loading mkt = sn\n",
      "loading mkt = l\n",
      "loading mkt = pp\n",
      "loading mkt = v\n",
      "loading mkt = TA\n",
      "loading mkt = sc\n",
      "loading mkt = m\n",
      "loading mkt = RM\n",
      "loading mkt = y\n",
      "loading mkt = p\n",
      "loading mkt = OI\n",
      "loading mkt = a\n",
      "loading mkt = c\n",
      "loading mkt = CF\n",
      "loading mkt = jd\n",
      "loading mkt = AP\n",
      "loading mkt = SM\n",
      "loading mkt = SF\n",
      "loading mkt = ss\n",
      "loading mkt = CJ\n",
      "loading mkt = UR\n",
      "loading mkt = eb\n",
      "loading mkt = eg\n",
      "loading mkt = pg\n",
      "continuous contract stopped at pg2010 for start = 2020-09-05, expiry= 2020-09-07\n",
      "loading mkt = T\n",
      "loading mkt = PK\n",
      "loading mkt = PF\n",
      "loading mkt = lh\n",
      "continuous contract stopped at lh2107 for start = 2021-05-01, expiry= 2021-06-07\n",
      "loading mkt = MA\n",
      "loading mkt = SR\n",
      "loading mkt = cs\n",
      "loading mkt = TF\n",
      "loading mkt = lu\n",
      "continuous contract stopped at lu2012 for start = 2020-10-01, expiry= 2020-10-26\n",
      "loading mkt = fu\n",
      "loading mkt = rb\n",
      "loading mkt = hc\n",
      "loading mkt = i\n",
      "loading mkt = j\n",
      "loading mkt = jm\n",
      "loading mkt = ru\n",
      "loading mkt = FG\n",
      "loading mkt = cu\n",
      "loading mkt = al\n",
      "loading mkt = zn\n",
      "loading mkt = pb\n",
      "loading mkt = ni\n",
      "loading mkt = sn\n",
      "loading mkt = l\n",
      "loading mkt = pp\n",
      "loading mkt = v\n",
      "loading mkt = TA\n",
      "loading mkt = sc\n",
      "loading mkt = m\n",
      "loading mkt = RM\n",
      "loading mkt = y\n",
      "loading mkt = p\n",
      "loading mkt = OI\n",
      "loading mkt = a\n",
      "loading mkt = c\n",
      "loading mkt = CF\n",
      "loading mkt = jd\n",
      "loading mkt = AP\n",
      "loading mkt = SM\n",
      "loading mkt = SF\n",
      "loading mkt = ss\n",
      "loading mkt = CJ\n",
      "loading mkt = UR\n",
      "loading mkt = eb\n",
      "loading mkt = eg\n",
      "loading mkt = pg\n",
      "loading mkt = T\n",
      "loading mkt = PK\n",
      "loading mkt = PF\n",
      "loading mkt = lh\n",
      "loading mkt = MA\n",
      "loading mkt = SR\n",
      "loading mkt = cs\n",
      "loading mkt = TF\n",
      "loading mkt = lu\n",
      "loading mkt = fu\n",
      "loading mkt = rb\n",
      "loading mkt = hc\n",
      "loading mkt = i\n",
      "loading mkt = j\n",
      "loading mkt = jm\n",
      "loading mkt = ru\n",
      "loading mkt = FG\n",
      "loading mkt = cu\n",
      "loading mkt = al\n",
      "loading mkt = zn\n",
      "loading mkt = pb\n",
      "loading mkt = ni\n",
      "loading mkt = sn\n",
      "loading mkt = l\n",
      "loading mkt = pp\n",
      "loading mkt = v\n",
      "loading mkt = TA\n",
      "loading mkt = sc\n",
      "loading mkt = m\n",
      "loading mkt = RM\n",
      "loading mkt = y\n",
      "loading mkt = p\n",
      "loading mkt = OI\n",
      "loading mkt = a\n",
      "loading mkt = c\n",
      "loading mkt = CF\n",
      "loading mkt = jd\n",
      "loading mkt = AP\n",
      "loading mkt = SM\n",
      "loading mkt = SF\n",
      "loading mkt = ss\n",
      "loading mkt = CJ\n",
      "loading mkt = UR\n",
      "loading mkt = eb\n",
      "loading mkt = eg\n",
      "loading mkt = pg\n",
      "loading mkt = T\n",
      "loading mkt = PK\n",
      "loading mkt = PF\n",
      "loading mkt = lh\n",
      "loading mkt = MA\n",
      "loading mkt = SR\n",
      "loading mkt = cs\n",
      "loading mkt = TF\n",
      "loading mkt = lu\n",
      "loading mkt = fu\n"
     ]
    }
   ],
   "source": [
    "edate=datetime.date(2023,1,20)\n",
    "start_date = day_shift(edate, '-30m')\n",
    "\n",
    "run_settings = [\n",
    "    ('commod_cal', commod_mkts, scenarios_all, 'CAL_30b', 's1'),\n",
    "    ('commod_hot', commod_mkts, scenarios_all, 'hot', 'd1'),\n",
    "    ('commod_exp', commod_mkts, scenarios_all, 'expiry', 'd1'),\n",
    "]\n",
    "\n",
    "res = {}\n",
    "for (fact_key, fact_mkts, scenarios, roll_label, freq) in run_settings:\n",
    "    res[fact_key] = update_factor_data(fact_mkts, scenarios, start_date, edate, roll_rule=roll_label, freq=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "posfile = '%s%s_%s.json' % (pos_loc, port_file, pos_date)\n",
    "\n",
    "with open(\"C:/dev/data/new_strat.json\", 'w') as f:\n",
    "    json.dump(res, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_chg_notification = ['PT_FACTPORT3_CAL_30b', 'PT_FACTPORT1_hot']\n",
    "port_pos_config = [\n",
    "    ('PT_FACTPORT3', 'C:/dev/pyktrader3/process/pt_test3/', 4600, 'CAL_30b', 's1'),\n",
    "    ('PT_FACTPORT1', 'C:/dev/pyktrader3/process/pt_test3/', 4600, 'CAL_30b', 's1'),\n",
    "    ('PT_FACTPORT3', 'C:/dev/pyktrader3/process/pt_test3/', 4600, 'hot', 'd1'),\n",
    "    ('PT_FACTPORT1', 'C:/dev/pyktrader3/process/pt_test3/', 4600, 'hot', 'd1'),\n",
    "    ('PT_FACTPORT3', 'C:/dev/pyktrader3/process/pt_test3/', 4600, 'expiry', 'd1'),\n",
    "    ('PT_FACTPORT1', 'C:/dev/pyktrader3/process/pt_test3/', 4600, 'expiry', 'd1'),\n",
    "]\n",
    "\n",
    "edate=datetime.date(2023,1,31)\n",
    "target_pos = {}\n",
    "pos_sum = {}\n",
    "for (port_name, pos_loc, pos_scaler, roll, freq) in port_pos_config:\n",
    "    port_file = port_name + '_' + roll\n",
    "    config_file = f'{pos_loc}settings/{port_name}.json'\n",
    "    with open(config_file, 'r') as fp:\n",
    "        strat_conf = json.load(fp)\n",
    "    strat_args = strat_conf['config']\n",
    "    assets = strat_args['assets']\n",
    "    factor_repo = strat_args['factor_repo']\n",
    "    product_list = []\n",
    "    \n",
    "    for asset_dict in assets:\n",
    "        under = asset_dict[\"underliers\"][0]\n",
    "        product = inst2product(under)\n",
    "        product_list.append(product)\n",
    "\n",
    "\n",
    "    target_pos, pos_sum = generate_daily_position(edate, product_list, factor_repo,\n",
    "                                                  roll_label=roll,\n",
    "                                                  pos_scaler=pos_scaler,\n",
    "                                                  freq=freq,\n",
    "                                                  hist_fact_lookback=20)\n",
    "    pos_date = day_shift(edate, '1b', CHN_Holidays)\n",
    "    pre_date = day_shift(pos_date, '-1b', CHN_Holidays)\n",
    "    pos_date = pos_date.strftime('%Y%m%d')\n",
    "    pre_date = pre_date.strftime('%Y%m%d')\n",
    "    posfile = '%s%s_%s.json' % (pos_loc, port_file, pos_date)\n",
    "    with open(posfile, 'w') as ofile:\n",
    "        json.dump(target_pos, ofile, indent=4)\n",
    "    pos_sum.index.name = 'factor'\n",
    "    pos_sum.to_csv('%spos_by_strat_%s_%s.csv' % (pos_loc, port_file, pos_date))\n",
    "    if port_file in pos_chg_notification:\n",
    "        with open('%s%s_%s.json' % (pos_loc, port_file, pre_date), 'r') as fp:\n",
    "            curr_pos = json.load(fp)\n",
    "\n",
    "        pos_df = pd.DataFrame({'cur': curr_pos, 'tgt': target_pos})\n",
    "\n",
    "        pos_df['diff'] = pos_df['tgt'] - pos_df['cur']\n",
    "\n",
    "        pos_update[port_file] = pos_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycmqlib3.utility.email_tool import send_html_by_smtp\n",
    "from pycmqlib3.utility.sec_bits import EMAIL_HOTMAIL\n",
    "\n",
    "\n",
    "job_status={\n",
    "    \"fut_daily\": {\n",
    "        \"DCE\": True,\n",
    "        \"CFFEX\": True,\n",
    "        \"CZCE\": True,\n",
    "        \"SHFE\": True,\n",
    "        \"INE\": True,\n",
    "        \"GFEX\": True\n",
    "    },\n",
    "    \"fact_repo\": {\n",
    "        \"commod_cal\": True\n",
    "    }\n",
    "}\n",
    "edate=datetime.date(2023,1,31)\n",
    "sub = 'EOD pos and job status<%s>' % (edate.strftime('%Y.%m.%d'))\n",
    "html = \"<html><head></head><body><p><br>\"\n",
    "for key in pos_update:\n",
    "    html += \"Position change for %s:<br>%s\" % (key, pos_update[key].to_html())\n",
    "html += \"Job status: %s <br>\" % (json.dumps(job_status))\n",
    "html +=\"</p></body></html>\"\n",
    "send_html_by_smtp(EMAIL_HOTMAIL, ['harveywu@gmail.com'], sub, html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel sheets updating and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import win32com.client as win32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import win32com.client as win32\n",
    "excel = win32.gencache.EnsureDispatch('Excel.Application')\n",
    "outfile = 'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\n",
    "wb = excel.Workbooks.Open(outfile)\n",
    "excel.CalculateUntilAsyncQueriesDone()\n",
    "wb.Save()\n",
    "wb.Close()\n",
    "excel.Quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlapp = win32.gencache.EnsureDispatch(\"Excel.Application\")\n",
    "xlapp.Interactive = False\n",
    "xlapp.Application.EnableEvents = False\n",
    "xlapp.DisplayAlerts = False  # Suppress any Alert windows, which require User action\n",
    "xlapp.AskToUpdateLinks = True # Disable automatic update linking\n",
    "xlapp.Visible = True  # Run the Application in the background\n",
    "\n",
    "outfile = 'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\n",
    "wb_7 = xlapp.Workbooks.Open(outfile)\n",
    "wb_7.RefreshAll()\n",
    "xlapp.CalculateUntilAsyncQueriesDone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\n",
    "pd.read_excel(outfile, index_col=None, skiprows=[0, 1, 3, 4, 5, 6, 7],sheet_name='base_inv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlapp.Interactive = True\n",
    "xlapp.DisplayAlerts = True  # Suppress any Alert windows, which require User action\n",
    "xlapp.AskToUpdateLinks = True  # Disable automatic update linking\n",
    "xlapp.Application.EnableEvents = True\n",
    "xlapp.Visible = True  # Run the Application in the background\n",
    "xlapp.Quit()    # Close Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the Excel file\n",
    "workbook = openpyxl.load_workbook('C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx')\n",
    "\n",
    "time.sleep(10)\n",
    "# Select the sheet\n",
    "for sheet_name in ['ferrous_inv1', 'ferrous_inv2', 'base_inv1', 'base_inv2']:\n",
    "    sheet = workbook[sheet_name]\n",
    "    sheet.calculate_dimension()\n",
    "    time.sleep(10)\n",
    "#     # Refresh formulas in cells A1 to A10\n",
    "#     sheet.refresh_all_formulas(ranges=['A1:A10'])\n",
    "    \n",
    "\n",
    "# Save the changes\n",
    "workbook.save('ifind_inv.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check upcoming nearby rolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.date(2023, 1, 3) # datetime.date.today()\n",
    "start_date = misc.day_shift(end_date, '-120d')\n",
    "print(start_date, end_date)\n",
    "\n",
    "roll_dict = {\n",
    "    'm': 30,\n",
    "    'RM': 30,\n",
    "    'rb': 30,\n",
    "    'ru': 30,\n",
    "    'sc': 20,\n",
    "    'lu': 45,\n",
    "    'eb': 20,\n",
    "    'eg': 30,\n",
    "    'cu': 25,\n",
    "    'jd': 40,\n",
    "    'lh': 40,\n",
    "    'T': 20,\n",
    "    'pg': 30,\n",
    "}\n",
    "\n",
    "shift_scope = 15\n",
    "for prod in ['m', 'RM', 'rb', 'sc', 'lu', 'eb', 'eg', 'cu', 'jd', 'lh', 'T','pg']:\n",
    "    test_roll = roll_dict[prod] + shift_scope\n",
    "    nc_df1 = misc.nearby(prod, 1, start_date = start_date, end_date = end_date, roll_rule = f'-{test_roll}b',shift_mode=1)    \n",
    "    curr_cont = nc_df1['contract'][-shift_scope-1]\n",
    "    for i in range(shift_scope, 0, -1):\n",
    "        if curr_cont != nc_df1['contract'][-i]:\n",
    "            print('%s roll into %s in %s bzdays for current roll rule (%s)' % \n",
    "                  (curr_cont, nc_df1['contract'][-i], shift_scope - i, f'-{roll_dict[prod]}b'))\n",
    "            #print(nc_df1.tail(10))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('C:\\\\dev\\\\pyktrader3\\\\process\\\\option_test\\\\volgrids_IO_220715.csv', header=None)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_columns', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check contract by product (for OI/volume evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_fut_by_product('zn', 'SHFE', datetime.date(2022,12,30),datetime.date(2023,1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKShare load future daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_scripts.aks_data_update import update_hist_fut_daily, update_spot_daily, \\\n",
    "                            update_exch_receipt_table, update_exch_inv_table, update_rank_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_hist_fut_daily(datetime.date(2022,12,3), datetime.date(2023,1,3), exchanges = ['GFEX'], flavor = 'mysql', fut_table = 'fut_daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.get_futures_daily(start_date = \"20230103\", end_date = \"20230103\", market = \"SHFE\")\n",
    "\n",
    "# ak.get_futures_daily(start_date='20230103',end_date='20230106', market='DCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check nearby rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020,1,2)\n",
    "end_date = datetime.date(2022,10,14)\n",
    "nc_df1 = misc.nearby('pg', 1, start_date = start_date, end_date = end_date, roll_rule='-32b',shift_mode=1)\n",
    "#nc_df2 = misc.nearby('pg', 1, start_date = start_date, end_date = end_date, roll_rule='-30b',shift_mode=1)\n",
    "\n",
    "nc_df1 #, nc_df2\n",
    "#nc1_df = misc.nearby('al', 2, start_date = start_date, end_date = end_date, roll_rule='-20b',shift_mode=1)\n",
    "#nc2_df = misc.nearby('al', 2, start_date = start_date, end_date = end_date, roll_rule='-20b',shift_mode=2)\n",
    "#print(nc_df, nc1_df, nc2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2021,1,1)\n",
    "end_date = datetime.date(2022,6,28)\n",
    "\n",
    "#load_fut_by_product('i', 'DCE', start_date ,end_date, freq = 'd')\n",
    "\n",
    "prodcode = 'sc'\n",
    "df1 = dataseries.nearby(prodcode, n = 1, start_date = start_date, end_date = end_date,\n",
    "           roll_rule = '-25b', freq = 'd', shift_mode = 1, \n",
    "           adj_field = 'close', calc_fields = ['open', 'close', 'high', 'low'], \n",
    "           fill_cont = False,\n",
    "          )\n",
    "\n",
    "df2 = misc.nearby(prodcode, n = 1, start_date = start_date, end_date = end_date, roll_rule = '-25b', freq = 'd', shift_mode = 1)\n",
    "\n",
    "print(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is testing for new nearby rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmqlib3.utility.dataseries import *\n",
    "\n",
    "ferrous_products_mkts = ['rb', 'hc', 'i', 'j', 'jm']\n",
    "ferrous_mixed_mkts = ['ru', 'FG', 'ZC', 'SM', \"SF\", 'nr']\n",
    "base_metal_mkts = ['cu', 'al', 'zn', 'pb', 'ni', 'sn', 'ss']\n",
    "precious_metal_mkts = ['au', 'ag']\n",
    "ind_metal_mkts = ferrous_products_mkts + ferrous_mixed_mkts + base_metal_mkts  \n",
    "petro_chem_mkts = ['l', 'pp', 'v', 'TA', 'MA', 'bu', 'sc', 'fu', 'eg', 'eb', 'lu', 'pg', 'PF'] \n",
    "ind_all_mkts = ind_metal_mkts + petro_chem_mkts\n",
    "ags_oil_mkts = ['m', 'RM', 'y', 'p', 'OI', 'a', 'c', 'cs', 'b'] #, 'b']\n",
    "ags_soft_mkts = ['CF', 'SR', 'jd', 'AP', 'sp', 'CJ', 'UR', 'SA', 'lh', 'PK',] # 'CY',] \n",
    "ags_all_mkts = ags_oil_mkts + ags_soft_mkts\n",
    "eq_fut_mkts = ['IF', 'IH', 'IC', 'IM',]\n",
    "bond_fut_mkts = ['T', 'TF', 'TS']\n",
    "fin_all_mkts = eq_fut_mkts + bond_fut_mkts\n",
    "commod_all_mkts = ind_all_mkts + ags_all_mkts + precious_metal_mkts\n",
    "all_markets = commod_all_mkts + fin_all_mkts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_dict = {\n",
    "    'rb': [datetime.date(2009,8,13), datetime.date(2009,8,13), 5000, '-20b'], \n",
    "    'hc': [datetime.date(2014,3,21), datetime.date(2015,12,11), 5000, '-20b'],\n",
    "    'i': [datetime.date(2013,10,18), datetime.date(2014,4,10), 5000, '-20b'],\n",
    "    'j': [datetime.date(2011,4,15), datetime.date(2012,5,7), 5000, '-20b'],\n",
    "    'jm': [datetime.date(2013,3,22), datetime.date(2013,3,22), 5000, '-20b'],\n",
    "    'ru': [datetime.date(2008,10,10), datetime.date(2008,10,10), 5000, '-20b'], \n",
    "    'FG': [datetime.date(2012,12,7), datetime.date(2012,12,7), 5000, '-20b'], \n",
    "    'ZC': [datetime.date(2013,9,26), datetime.date(2013,9,26), 5000, '-20b'],\n",
    "    'SM': [datetime.date(2016,7,26), datetime.date(2016,10,11), 5000, '-20b'], \n",
    "    'SF': [datetime.date(2016,7,27), datetime.date(2017,3,13), 5000, '-20b'],    \n",
    "    'nr': [datetime.date(2019,8,12), datetime.date(2019,8,12), 5000, '-20b'],\n",
    "    'cu': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'], \n",
    "    'al': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'zn': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'pb': [datetime.date(2014,7,25), datetime.date(2014,7,25), 5000, '-20b'],\n",
    "    'ni': [datetime.date(2015,6,17), datetime.date(2015,6,17), 5000, '-20b'], \n",
    "    'sn': [datetime.date(2017,5,2), datetime.date(2017,5,2), 5000, '-20b'],\n",
    "    'ss': [datetime.date(2019,9,25), datetime.date(2020, 1, 6), 5000, '-20b'],\n",
    "    \n",
    "    'l': [datetime.date(2008,1,18), datetime.date(2010,4,14), 5000, '-20b'],\n",
    "    'pp': [datetime.date(2014,2,28), datetime.date(2014,2,28), 5000, '-20b'], \n",
    "    'v': [datetime.date(2009,5,25), datetime.date(2010,8,16), 5000, '-20b'],   \n",
    "    'TA': [datetime.date(2007,7,10), datetime.date(2008,7,10), 5000, '-20b'],\n",
    "    'MA': [datetime.date(2011,10,28), datetime.date(2013,10,22), 5000, '-20b'], \n",
    "    'sc': [datetime.date(2018, 3, 26), datetime.date(2018,8,30), 5000, '-20b'],\n",
    "    'bu': [datetime.date(2015, 1,16), datetime.date(2015,7,1), 5000, '-20b'],\n",
    "    'fu': [datetime.date(2018, 7, 17), datetime.date(2018,10,10), 5000, '-20b'],\n",
    "    'lu': [datetime.date(2020, 10, 9), datetime.date(2020, 10, 9), 5000, '-20b'], \n",
    "    'eb': [datetime.date(2020, 5, 6), datetime.date(2020, 6, 1), 5000, '-20b'],\n",
    "    'eg': [datetime.date(2019, 4, 2), datetime.date(2019, 4, 2), 5000, '-20b'],\n",
    "    'pg': [datetime.date(2020, 9, 7), datetime.date(2020, 9, 7), 5000, '-20b'],\n",
    "    'PF': [datetime.date(2021,1,5), datetime.date(2021,3,1), 5000, '-20b'],\n",
    "        \n",
    "    'a': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'b': [datetime.date(2019,7,1), datetime.date(2019,7,1), 5000, '-20b'],\n",
    "    'm': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'RM': [datetime.date(2012,12,28), datetime.date(2012,12,28), 5000, '-20b'], \n",
    "    'y': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],  \n",
    "    'p':  [datetime.date(2008,1,2), datetime.date(2008,1,2), 4000, '-20b'], \n",
    "    'OI': [datetime.date(2013,2,21), datetime.date(2013,2,21), 5000, '-20b'], \n",
    "    'c': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'cs': [datetime.date(2014,12,19), datetime.date(2014,12,19), 5000, '-20b'], \n",
    "    \n",
    "    'UR': [datetime.date(2019, 8, 9), datetime.date(2019, 8, 9), 5000, '-20b'],\n",
    "    'SA': [datetime.date(2019,12,6), datetime.date(2019,12,6), 5000, '-20b'],\n",
    "    'CF': [datetime.date(2008,7,14), datetime.date(2008,7,14), 5000, '-20b'], \n",
    "    'CY': [datetime.date(2017, 9, 1), datetime.date(2017, 9, 1), 5000, '-20b'],\n",
    "    'SR': [datetime.date(2008,7,10), datetime.date(2008,7,10), 5000, '-20b'],\n",
    "    'AP': [datetime.date(2017,12,22), datetime.date(2017,12,22), 5000, '-20b'],\n",
    "    'jd': [datetime.date(2013,11,8), datetime.date(2013,11,8), 5000, '-20b'], \n",
    "    'lh': [datetime.date(2021,1,8), datetime.date(2021,1,8), 5000, '-20b'],    \n",
    "    'PK': [datetime.date(2021,2,1), datetime.date(2021,2,1), 5000, '-20b'],\n",
    "    'CJ': [datetime.date(2019,4,30), datetime.date(2019,4,30), 5000, '-20b'],\n",
    "    'rr': [datetime.date(2019, 9, 1), datetime.date(2019, 9, 1), 5000, '-20b'],\n",
    "    'sp': [datetime.date(2018,11,27), datetime.date(2018,11,27), 5000, '-20b'],\n",
    "    \n",
    "    'au': [datetime.date(2010,1,4), datetime.date(2015,1,16), 5000, '-20b'],\n",
    "    'ag': [datetime.date(2012,5,10), datetime.date(2019,6,26), 5000, '-20b'],\n",
    "    'IF': [datetime.date(2010,5,1), datetime.date(2010,5,1), 5000, '-20b'], \n",
    "    'IH': [datetime.date(2015,5,1), datetime.date(2015,5,1), 5000, '-20b'], \n",
    "    'IC': [datetime.date(2015,5,1), datetime.date(2015,5,1), 5000, '-20b'], \n",
    "    'TF': [datetime.date(2019,6,1), datetime.date(2019,6,1), 5000, '-20b'],\n",
    "    'T': [datetime.date(2019,4,1), datetime.date(2019,4,1), 5000, '-20b'], \n",
    "    'TS': [datetime.date(2018, 9, 1), datetime.date(2018, 9, 1), 5000, '-20b'],\n",
    "    'PM': [datetime.date(2013,10,1), datetime.date(2013,10,1), 5000, '-20b'], \n",
    "    'RI': [datetime.date(2013,1,1), datetime.date(2013,1,1), 5000, '-20b'], \n",
    "    'WH': [datetime.date(2014,5,1), datetime.date(2014,5,1), 5000, '-20b'], \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# script to batch generate nearby rolling csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2008,1,1)\n",
    "end_date = datetime.date(2022,7,22)\n",
    "freq = 'd'\n",
    "roll_mode = 0\n",
    "nb_cont = 2\n",
    "\n",
    "#sn need to fix 2019-12\n",
    "# IF IC IH need to roll quarterly and how to roll monthly\n",
    "roll_name = 'nroll'\n",
    "roll_win = 3\n",
    "cont_thres = 50_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "folder = \"C:\\\\dev\\\\pyktrader3\\\\data\\\\carry\"\n",
    "for prodcode in commod_all_mkts: #bond_fut_mkts: #: # petro_chem_mkts\n",
    "    min_thres = 7_500\n",
    "    roll_cutoff = '-20b'\n",
    "    contract_filter = None\n",
    "    if prodcode in ['IF', 'IC', 'IH', 'sc',]:\n",
    "        min_thres = 0.1 * min_thres\n",
    "    elif prodcode in ['j', 'ni', 'sn', 'cu', 'bc', 'lh']:\n",
    "        min_thres = 0.2 * min_thres\n",
    "    elif prodcode in ['ru', 'nr', 'al', 'zn', 'pb', 'jm', 'ss', 'PK', 'b',]:\n",
    "        min_thres = 0.5 * min_thres\n",
    "    elif prodcode in ['SM', 'SF', 'FG', 'i', 'AP', 'eb', ]:\n",
    "        min_thres = 0.8 * min_thres\n",
    "    elif prodcode in ['T', 'TF', 'TS']:\n",
    "        min_thres = 0\n",
    "    if prodcode in ['IF', 'IC', 'IH']:\n",
    "        roll_cutoff = '0b'\n",
    "\n",
    "#     if prodcode in ['j', ]:\n",
    "#         contract_filter = prod_main_cont_filter\n",
    "    roll_kwargs = {'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "                   'contract_filter': contract_filter, 'min_thres': min_thres}\n",
    "    df = load_processed_fut_by_product(prodcode, start_date=start_date, end_date=end_date, freq=freq, **roll_kwargs)\n",
    "    roll_map, daily_cont = rolling_fut_cont(df, nb_cont=nb_cont, cont_thres=cont_thres, roll_mode=roll_mode)\n",
    "    if roll_map.iloc[-1, 1] == None:\n",
    "        roll_map.iat[-1, 1] = misc.default_next_main_contract(roll_map.iloc[-1, 0], start_date, end_date)\n",
    "    flag = roll_map[1].isna()\n",
    "    print(prodcode, roll_map)\n",
    "    roll_map.loc[flag, 1] = roll_map.loc[flag.shift(1).fillna(False), 0].values\n",
    "    file_name = \"%s\\\\%s_%s.csv\" % (folder, prodcode, roll_name) \n",
    "    roll_map.to_csv(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single product rolling testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2010,1,1)\n",
    "end_date = datetime.date(2022,7,15)\n",
    "freq = 'd'\n",
    "roll_mode = 0\n",
    "nb_cont = 2\n",
    "\n",
    "roll_name = 'nroll'\n",
    "roll_win = 3\n",
    "cont_thres = 50_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "\n",
    "prodcode = 'rb'\n",
    "min_thres = 7_500\n",
    "roll_cutoff = '-20b'\n",
    "contract_filter = None\n",
    "\n",
    "roll_kwargs = {'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "               'contract_filter': contract_filter, 'min_thres': min_thres}\n",
    "df = load_processed_fut_by_product(prodcode, start_date=start_date, end_date=end_date, freq=freq, **roll_kwargs)\n",
    "roll_map, daily_cont = rolling_fut_cont(df, nb_cont=nb_cont, cont_thres=cont_thres, roll_mode=roll_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_date = datetime.date(2022,9,22)\n",
    "shift_mode = 1\n",
    "\n",
    "roll_mode = 0\n",
    "roll_name = 'nroll'\n",
    "nb_cont = 2\n",
    "\n",
    "roll_win = 3\n",
    "cont_thres = 50_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "\n",
    "min_thres = 0\n",
    "roll_cutoff = '-5b'\n",
    "contract_filter = None\n",
    "    \n",
    "folder = \"C:\\\\dev\\\\pyktrader3\\\\data\\\\carry\"\n",
    "\n",
    "data_df = pd.DataFrame()\n",
    "for prodcode in ['rb', 'hc', 'i', 'j']: \n",
    "    if prodcode in ['IF', 'IC', 'IH', 'sc',]:\n",
    "        min_thres = 0.1 * min_thres\n",
    "    elif prodcode in ['j', 'ni', 'sn', 'cu', 'bc', 'lh']:\n",
    "        min_thres = 0.2 * min_thres\n",
    "    elif prodcode in ['ru', 'nr', 'al', 'zn', 'pb', 'jm', 'ss', 'PK', 'b',]:\n",
    "        min_thres = 0.5 * min_thres\n",
    "    elif prodcode in ['SM', 'SF', 'FG', 'i', 'AP', 'eb', ]:\n",
    "        min_thres = 0.8 * min_thres\n",
    "    elif prodcode in ['T', 'TF', 'TS']:\n",
    "        min_thres = 0\n",
    "    if prodcode in ['IF', 'IC', 'IH']:\n",
    "        roll_cutoff = '0b'\n",
    "    roll_kwargs = {'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "                   'contract_filter': contract_filter, 'min_thres': min_thres}\n",
    "    \n",
    "    setting = setting_dict[prodcode]\n",
    "    file_name = \"%s\\\\%s_%s.csv\" % (folder, prodcode, roll_name) \n",
    "    roll_map = pd.read_csv(file_name).set_index('date')\n",
    "    nb_df = nearby_series(prodcode, start_date=setting[0], end_date = end_date, shift_mode = shift_mode,\n",
    "                  freq='d', roll_kwargs=roll_kwargs, roll_map = roll_map)\n",
    "    for key in nb_df:\n",
    "        fields = nb_df[key].columns\n",
    "        nb_df[key]['product'] = prodcode\n",
    "        nb_df[key]['code'] = key\n",
    "        data_df = data_df.append(nb_df[key])\n",
    "print(fields)    \n",
    "#     df = pd.concat([nb_df[key] for key in nb_df],axis=1)\n",
    "#     df.to_csv(\"%s\\\\combined_%s_%s.csv\" % (folder, prodcode, roll_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(data_df.reset_index(), index='date', columns = ['product', 'code'], values = list(fields), aggfunc = 'last')\n",
    "df = df.reorder_levels([1, 2, 0], axis=1).sort_index(axis=1)\n",
    "df.columns.rename(['field', 'product', 'code'], inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df.columns[(df.columns.get_level_values(2) == 'close') & (df.columns.get_level_values(1) == 'c0')]].droplevel([1, 2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodcode = 'i'\n",
    "\n",
    "start_date = datetime.date(2014,1,1)\n",
    "end_date = datetime.date(2022,6,30)\n",
    "\n",
    "freq = 'd'\n",
    "shift_mode = 1\n",
    "contract_filter = None # prod_main_cont_exch\n",
    "roll_mode = 0\n",
    "nb_cont = 2\n",
    "\n",
    "roll_win = 3\n",
    "roll_cutoff = '-20b'\n",
    "min_thres = 5_000\n",
    "cont_thres = 40_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "\n",
    "nb_df= nearby_series(prodcode, start_date=start_date, end_date=end_date, shift_mode=shift_mode,\n",
    "                     nb_cont=nb_cont, cont_thres=cont_thres, roll_mode=roll_mode,freq=freq, \n",
    "                     roll_kwargs={'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "                                  'contract_filter': contract_filter, 'min_thres': min_thres})\n",
    "print(nb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is for backtest metric testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2018, 1, 2)\n",
    "end_date = datetime.date(2022,7,18)\n",
    "shift_mode = 1\n",
    "\n",
    "roll_mode = 0\n",
    "roll_name = 'nroll'\n",
    "nb_cont = 2\n",
    "\n",
    "prodcode = 'rb'\n",
    "\n",
    "roll_kwargs = {'roll_win': 3, 'roll_cutoff': '-5b', 'cont_ratio': [1.0, 0.0],\n",
    "               'contract_filter': None, 'min_thres': 0}\n",
    "\n",
    "folder = \"C:\\\\dev\\\\pyktrader3\\\\data\\\\carry\"\n",
    "file_name = \"%s\\\\%s_%s.csv\" % (folder, prodcode, roll_name) \n",
    "roll_map = pd.read_csv(file_name).set_index('date')\n",
    "\n",
    "nb_df = nearby_series(prodcode, start_date=start_date, end_date = end_date, shift_mode = shift_mode,\n",
    "              freq='d', roll_kwargs=roll_kwargs, roll_map = roll_map)\n",
    "print(nb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = nb_df['c0']\n",
    "\n",
    "xdf['holding'] = (xdf['price_chg'] - xdf['price_chg'].rolling(14).mean()).shift(1).fillna(0)\n",
    "xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsBase(xdf['holding'].to_frame('rb'), xdf['price_chg'].to_frame('rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_pnl = metrics._lagged_portfolio_pnl().to_frame(name='total')\n",
    "portfolio_pnl['Month'] = portfolio_pnl.index.month\n",
    "portfolio_pnl.index = [i.replace(month=1) for i in portfolio_pnl.index]\n",
    "seasonal_pnl = portfolio_pnl.pivot(columns = 'Month', values = 'total').fillna(0.0)\n",
    "print(seasonal_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#seasonal_pnl.plot(x=seasonal_pnl.index.astype(str))\n",
    "seasonal_pnl.set_index(seasonal_pnl.index.astype('str')).plot(rot=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.holdings, metrics.returns\n",
    "# res = metrics.seasonal_pnl()\n",
    "res_df = metrics.lead_lag()\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = res_df['leadlag_sharpes'].loc['fullsample']\n",
    "ax = ts.plot(kind='bar',figsize=(6, 6))\n",
    "new_ticks = np.linspace(-20, 60, 17)\n",
    "ax.set_xticks(np.interp(new_ticks, ts.index, np.arange(ts.size)))\n",
    "ax.set_xticklabels(new_ticks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metrics.lagged_pnl(lags=[1,2,5,10,20])\n",
    "res['cumpnl'].plot()\n",
    "print(res['sharpe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metrics.smoothed_pnl(smooth_hls=[1, 2, 5, 10, 20])\n",
    "res['cumpnl'].plot()\n",
    "print(res['sharpe'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df['holding'].to_frame('al').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2021-01-04').replace(day=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar_aggregation(nb_df, period = 'weekly', how = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2014,1,1)\n",
    "end_date = datetime.date(2022,6,17)\n",
    "\n",
    "nb_df = dataseries.nearby('al', 1, start_date = start_date, end_date = end_date, roll_rule='-30b',shift_mode=1)\n",
    "#nb1_df = dataseries.nearby('sc', 2, start_date = start_date, end_date = end_date, roll_rule='-20b',shift_mode=1)\n",
    "#nb2_df = nearby('al', 2, start_date = start_date, end_date = end_date, roll_rule='-30b',shift_mode=2)\n",
    "print(nb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_fut_by_product('eg', 'DCE', datetime.date(2022,5,20) ,datetime.date(2022,5,20)))\n",
    "#print(load_fut_by_product('sc', 'INE', datetime.date(2022,3,2) ,datetime.date(2022,3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_df[nb1_df['instID'] == nb_df['instID']]\n",
    "#nb_df.close.plot(color='r')\n",
    "\n",
    "#nb1_df.close.plot(color='y')\n",
    "print(nb1_df.close.diff().max(), nb1_df.price_chg.max())\n",
    "#nb_df[['close']].plot()\n",
    "#flag = nb1_df.close.diff()>1.0\n",
    "#nb1_df[flag | flag.shift(-1)]\n",
    "#nb1_df.loc[datetime.date(2018,9,8):datetime.date(2018,9,20):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2011,1,1)\n",
    "end_date = datetime.date(2022, 1, 28)\n",
    "prodcode = 'ZC'\n",
    "roll_rule = '-30b'\n",
    "shift_mode = 1\n",
    "n = 1\n",
    "\n",
    "adj_field = 'close'\n",
    "calc_fields = ['open', 'close', 'high', 'low']\n",
    "contract_filter = [1, 5, 9]\n",
    "\n",
    "exch = misc.prod2exch(prodcode)\n",
    "xdf = load_fut_by_product(prodcode, exch, start_date ,end_date)\n",
    "xdf['expiry'] = xdf['instID'].apply(lambda x: misc.contract_expiry(x, hols = misc.CHN_Holidays))\n",
    "xdf['month'] = xdf['instID'].apply(lambda x: misc.inst2contmth(x)%100)\n",
    "xdf = xdf.sort_values(['instID', 'date'])\n",
    "\n",
    "if shift_mode == 2:\n",
    "    xdf['price_chg'] = np.log(xdf[adj_field]).diff()\n",
    "else:\n",
    "    xdf['price_chg'] = xdf[adj_field].diff()        \n",
    "xdf.loc[xdf['instID']!=xdf['instID'].shift(1), 'price_chg'] = 0\n",
    "if (roll_rule[0] == '-') and (roll_rule[-1] in ['b', 'd']):\n",
    "    xdf['roll_date'] = xdf['expiry'].apply(lambda x: misc.day_shift(x, roll_rule, hols = misc.CHN_Holidays))\n",
    "    xdf = xdf[xdf.date <= xdf['roll_date']]\n",
    "else:\n",
    "    xdf['roll_date'] = xdf['expiry']\n",
    "if contract_filter:\n",
    "    xdf = xdf[xdf.month.isin(contract_filter)]\n",
    "df = pd.pivot_table(xdf, index = 'date', columns = 'expiry', values = 'instID', aggfunc = 'first')\n",
    "df1 = df.apply(lambda x: pd.Series(x.dropna().values), axis=1)\n",
    "df1 = df1.reset_index()\n",
    "\n",
    "col_df = df1[['date', n-1]].rename(columns = {n-1: 'instID'})\n",
    "#if len(col_df[col_df['instID'].isna()])> 0:\n",
    "#    raise ValueError('There are nan values for product=%s, nearby=%s, roll=%s' % (prodcode, str(n), roll_rule))\n",
    "col_df = col_df.fillna(method = 'ffill')\n",
    "out_df = pd.merge(col_df, xdf,left_on = ['date', 'instID'], right_on=['date', 'instID'], how = 'left')\n",
    "\n",
    "if shift_mode > 0:\n",
    "    cum_adj = out_df.loc[::-1, 'price_chg'].cumsum().shift(1).fillna(0)[::-1]\n",
    "    if shift_mode == 2:\n",
    "        adj_price = out_df[adj_field].iloc[-1]/np.exp(cum_adj)\n",
    "        out_df['shift'] = np.log(adj_price) - np.log(out_df[adj_field])\n",
    "    else:\n",
    "        adj_price = out_df[adj_field].iloc[-1] - cum_adj\n",
    "        out_df['shift'] = adj_price - out_df[adj_field]    \n",
    "\n",
    "    for cfield in calc_fields:\n",
    "        if shift_mode == 2:\n",
    "            out_df[cfield] = out_df[cfield] * np.exp(out_df['shift'])\n",
    "        else:\n",
    "            out_df[cfield] = out_df[cfield] + out_df['shift']\n",
    "else:\n",
    "    out_df['shift'] = 0\n",
    "out_df = out_df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_fut_by_product('TA', 'CZCE', start_date ,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_df[out_df.instID.isna()]\n",
    "\n",
    "#out_df.loc[datetime.date(2017,11,20):datetime.date(2017,12,10),:]\n",
    "#out_df.close.plot()\n",
    "print(out_df.close.diff().max(),out_df.price_chg.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_adj = out_df.loc[::-1, 'price_chg'].cumsum().shift(1).fillna(0)[::-1]\n",
    "price_close = out_df['close'].iloc[-1] - price_adj\n",
    "price_shift = price_close - out_df['close']\n",
    "print(price_close, price_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = xdf.sort_values(['instID', 'date'])\n",
    "xdf['chg'] = xdf['close'].diff()\n",
    "flag = xdf['instID']!=xdf['instID'].shift(1)\n",
    "xdf.loc[flag, 'chg'] = 0\n",
    "print(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adf = df.iloc[:, df.columns.get_level_values(0)=='close']\n",
    "nb_df = nearby(adf, roll = 30)\n",
    "print(nb_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypfopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearby(prodcode, n = 1, start_date = None, end_date = None, \n",
    "           roll_rule = '-20b', shift_mode = 0, \n",
    "           adj_field = 'close', calc_fields = ['open', 'close', 'high', 'low'], \n",
    "           contract_filter = None, fill_cont = False,\n",
    "          ):\n",
    "    exch = misc.prod2exch(prodcode)\n",
    "    xdf = load_fut_by_product(prodcode, exch, start_date ,end_date)\n",
    "    xdf['expiry'] = xdf['instID'].apply(lambda x: misc.contract_expiry(x, hols = misc.CHN_Holidays))\n",
    "    xdf['month'] = xdf['instID'].apply(lambda x: misc.inst2contmth(x)%100)\n",
    "    xdf = xdf.sort_values(['instID', 'date'])\n",
    "\n",
    "    if shift_mode == 2:\n",
    "        xdf['price_chg'] = np.log(xdf[adj_field]).diff()\n",
    "    else:\n",
    "        xdf['price_chg'] = xdf[adj_field].diff()        \n",
    "    xdf.loc[xdf['instID']!=xdf['instID'].shift(1), 'price_chg'] = 0\n",
    "    if (roll_rule[0] == '-') and (roll_rule[-1] in ['b', 'd']):\n",
    "        xdf['roll_date'] = xdf['expiry'].apply(lambda x: misc.day_shift(x, roll_rule, hols = misc.CHN_Holidays))\n",
    "        xdf = xdf[xdf.date <= xdf['roll_date']]\n",
    "    else:\n",
    "        xdf['roll_date'] = xdf['expiry']\n",
    "    if contract_filter:\n",
    "        xdf = xdf[xdf.month.isin(contract_filter)]\n",
    "    df = pd.pivot_table(xdf, index = 'date', columns = 'expiry', values = 'instID', aggfunc = 'first')\n",
    "    df1 = df.apply(lambda x: pd.Series(x.dropna().values), axis=1)\n",
    "    df1 = df1.reset_index()\n",
    "    col_df = df1[['date', n-1]].rename(columns = {n-1: 'instID'})\n",
    "    if len(col_df[col_df['instID'].isna()])> 0:\n",
    "        if fill_cont:\n",
    "            col_df = col_df.fillna(method = 'ffill')\n",
    "        else:\n",
    "            raise ValueError('There are nan values for product=%s, nearby=%s, roll=%s' % (prodcode, str(n), roll_rule))\n",
    "    out_df = pd.merge(col_df, xdf,left_on = ['date', 'instID'], right_on=['date', 'instID'], how = 'left')\n",
    "    if shift_mode > 0:\n",
    "        cum_adj = out_df.loc[::-1, 'price_chg'].cumsum().shift(1).fillna(0)[::-1]\n",
    "        if shift_mode == 2:\n",
    "            adj_price = out_df[adj_field].iloc[-1]/np.exp(cum_adj)\n",
    "            out_df['shift'] = np.log(adj_price) - np.log(out_df[adj_field])\n",
    "        else:\n",
    "            adj_price = out_df[adj_field].iloc[-1] - cum_adj\n",
    "            out_df['shift'] = adj_price - out_df[adj_field]    \n",
    "\n",
    "        for cfield in calc_fields:\n",
    "            if shift_mode == 2:\n",
    "                out_df[cfield] = out_df[cfield] * np.exp(out_df['shift'])\n",
    "            else:\n",
    "                out_df[cfield] = out_df[cfield] + out_df['shift']\n",
    "    else:\n",
    "        out_df['shift'] = 0\n",
    "    out_df = out_df.set_index('date')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"C:/dev/wtdev/common/hots.json\", 'r') as infile:\n",
    "    config = json.load(infile)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame.from_records(config['CFFEX']['IF'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
