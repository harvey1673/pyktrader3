{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['PY3_PROD'] = '1'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.system('kinit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List\n",
    "import datetime\n",
    "from pycmqlib3.utility import misc\n",
    "\n",
    "from pycmqlib3.utility.dbaccess import *\n",
    "from pycmqlib3.utility import dataseries\n",
    "from pycmqlib3.analytics.tstool import *\n",
    "from pycmqlib3.analytics.btmetrics import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "#pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_contract_list_table(datetime.date(2023,1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load eod mark from exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_scripts.aks_data_update import update_hist_fut_daily\n",
    "\n",
    "update_hist_fut_daily(start_date=datetime.date(2022,12,22),\n",
    "                          end_date=datetime.date(2023,1,6),\n",
    "                          exchanges=['GFEX'],\n",
    "                          flavor='mysql',\n",
    "                          fut_table='fut_daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check factor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list = ['rb', 'hc', 'i', 'j', 'jm']\n",
    "roll_label = 'CAL_30b'\n",
    "freq = 's1'\n",
    "db_table = 'fut_fact_data'\n",
    "fact_list = [\"ryield_1_nmb_120\", \"basmom_100_nma_120\", \"basmom_170_nma_120\",\n",
    "            \"ryield_1_nma_20\", \"ryield_1_nma_110\"]\n",
    "start_date = datetime.date(2022,10,1)\n",
    "end_date = datetime.date(2022,12,30)\n",
    "df = load_factor_data(prod_list, \n",
    "                      factor_list = fact_list,\n",
    "                      roll_label = roll_label,\n",
    "                      start = start_date,\n",
    "                      end = end_date,\n",
    "                      freq = freq,\n",
    "                      db_table = db_table)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel sheets updating and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import win32com.client as win32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2147023170, 'The remote procedure call failed.', None, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_77496/2021962569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mexcel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwin32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgencache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnsureDispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Excel.Application'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mwb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexcel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWorkbooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mexcel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalculateUntilAsyncQueriesDone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mwb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\gen_py\\3.9\\00020813-0000-0000-C000-000000000046x0x1x9\\Workbooks.py\u001b[0m in \u001b[0;36mOpen\u001b[1;34m(self, Filename, UpdateLinks, ReadOnly, Format, Password, WriteResPassword, IgnoreReadOnlyRecommended, Origin, Delimiter, Editable, Notify, Converter, AddToMru, Local, CorruptLoad)\u001b[0m\n\u001b[0;32m     73\u001b[0m                         \u001b[1;33m,\u001b[0m \u001b[0mEditable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultNamedOptArg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultNamedOptArg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConverter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultNamedOptArg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAddToMru\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultNamedOptArg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLocal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultNamedOptArg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \t\t\t, CorruptLoad=defaultNamedOptArg):\n\u001b[1;32m---> 75\u001b[1;33m \t\tret = self._oleobj_.InvokeTypes(1923, LCID, 1, (13, 0), ((8, 1), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17), (12, 17)),Filename\n\u001b[0m\u001b[0;32m     76\u001b[0m                         \u001b[1;33m,\u001b[0m \u001b[0mUpdateLinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadOnly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPassword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWriteResPassword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                         \u001b[1;33m,\u001b[0m \u001b[0mIgnoreReadOnlyRecommended\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOrigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDelimiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEditable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147023170, 'The remote procedure call failed.', None, None)"
     ]
    }
   ],
   "source": [
    "\n",
    "import win32com.client as win32\n",
    "excel = win32.gencache.EnsureDispatch('Excel.Application')\n",
    "outfile = 'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\n",
    "wb = excel.Workbooks.Open(outfile)\n",
    "excel.CalculateUntilAsyncQueriesDone()\n",
    "wb.Save()\n",
    "wb.Close()\n",
    "excel.Quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlapp = win32.gencache.EnsureDispatch(\"Excel.Application\")\n",
    "xlapp.Interactive = False\n",
    "xlapp.Application.EnableEvents = False\n",
    "xlapp.DisplayAlerts = False  # Suppress any Alert windows, which require User action\n",
    "xlapp.AskToUpdateLinks = True # Disable automatic update linking\n",
    "xlapp.Visible = True  # Run the Application in the background\n",
    "\n",
    "outfile = 'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\n",
    "wb_7 = xlapp.Workbooks.Open(outfile)\n",
    "wb_7.RefreshAll()\n",
    "xlapp.CalculateUntilAsyncQueriesDone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx'\n",
    "pd.read_excel(outfile, index_col=None, skiprows=[0, 1, 3, 4, 5, 6, 7],sheet_name='base_inv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlapp.Interactive = True\n",
    "xlapp.DisplayAlerts = True  # Suppress any Alert windows, which require User action\n",
    "xlapp.AskToUpdateLinks = True  # Disable automatic update linking\n",
    "xlapp.Application.EnableEvents = True\n",
    "xlapp.Visible = True  # Run the Application in the background\n",
    "xlapp.Quit()    # Close Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the Excel file\n",
    "workbook = openpyxl.load_workbook('C:/Users/harvey/OneDrive/Documents/china_fundamentals/ifind_inv.xlsx')\n",
    "\n",
    "time.sleep(10)\n",
    "# Select the sheet\n",
    "# for sheet_name in ['ferrous_inv1', 'ferrous_inv2', 'base_inv1', 'base_inv2']:\n",
    "#     sheet = workbook[sheet_name]\n",
    "#     sheet.calculate_dimension()\n",
    "#     # Refresh formulas in cells A1 to A10\n",
    "#     #sheet.refresh_all_formulas(ranges=['A1:A10'])\n",
    "    \n",
    "\n",
    "# Save the changes\n",
    "workbook.save('ifind_inv.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check upcoming nearby rolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.date(2023, 1, 3) # datetime.date.today()\n",
    "start_date = misc.day_shift(end_date, '-120d')\n",
    "print(start_date, end_date)\n",
    "\n",
    "roll_dict = {\n",
    "    'm': 30,\n",
    "    'RM': 30,\n",
    "    'rb': 30,\n",
    "    'ru': 30,\n",
    "    'sc': 20,\n",
    "    'lu': 45,\n",
    "    'eb': 20,\n",
    "    'eg': 30,\n",
    "    'cu': 25,\n",
    "    'jd': 40,\n",
    "    'lh': 40,\n",
    "    'T': 20,\n",
    "    'pg': 30,\n",
    "}\n",
    "\n",
    "shift_scope = 15\n",
    "for prod in ['m', 'RM', 'rb', 'sc', 'lu', 'eb', 'eg', 'cu', 'jd', 'lh', 'T','pg']:\n",
    "    test_roll = roll_dict[prod] + shift_scope\n",
    "    nc_df1 = misc.nearby(prod, 1, start_date = start_date, end_date = end_date, roll_rule = f'-{test_roll}b',shift_mode=1)    \n",
    "    curr_cont = nc_df1['contract'][-shift_scope-1]\n",
    "    for i in range(shift_scope, 0, -1):\n",
    "        if curr_cont != nc_df1['contract'][-i]:\n",
    "            print('%s roll into %s in %s bzdays for current roll rule (%s)' % \n",
    "                  (curr_cont, nc_df1['contract'][-i], shift_scope - i, f'-{roll_dict[prod]}b'))\n",
    "            #print(nc_df1.tail(10))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('C:\\\\dev\\\\pyktrader3\\\\process\\\\option_test\\\\volgrids_IO_220715.csv', header=None)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_columns', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check contract by product (for OI/volume evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_fut_by_product('zn', 'SHFE', datetime.date(2022,12,30),datetime.date(2023,1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKShare load future daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_scripts.aks_data_update import update_hist_fut_daily, update_spot_daily, \\\n",
    "                            update_exch_receipt_table, update_exch_inv_table, update_rank_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_hist_fut_daily(datetime.date(2022,12,3), datetime.date(2023,1,3), exchanges = ['GFEX'], flavor = 'mysql', fut_table = 'fut_daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.get_futures_daily(start_date = \"20230103\", end_date = \"20230103\", market = \"SHFE\")\n",
    "\n",
    "# ak.get_futures_daily(start_date='20230103',end_date='20230106', market='DCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycmqlib3.utility.email_tool import *\n",
    "from pycmqlib3.utility.sec_bits import EMAIL_HOTMAIL\n",
    "send_email_by_smtp(EMAIL_HOTMAIL, ['harveywu@gmail.com'], 'test', 'hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wtpy.apps import WtHotPicker, WtCacheMonExchg, WtCacheMonSS, WtMailNotifier\n",
    "import json\n",
    "import datetime\n",
    "import logging\n",
    "from pycmqlib3.utility.sec_bits import EMAIL_HOTMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_hot_rules(end_date=None,\n",
    "                    files=[\"hots.json\", \"seconds.json\", \"marker.json\"],\n",
    "                    snapshot_loc=\"C:/dev/wtdev/storage/his/snapshot/\",\n",
    "                    notify=False):\n",
    "    # 增量更新主力合约切换规则\n",
    "    if snapshot_loc:\n",
    "        # 从datakit落地的行情快照直接读取\n",
    "        cacher = WtCacheMonSS(snapshot_loc)\n",
    "    else:\n",
    "        # 从交易所官网拉取行情快照\n",
    "        cacher = WtCacheMonExchg()\n",
    "\n",
    "    picker = WtHotPicker(hotFile=files[0], secFile=files[1], markerFile=files[2])\n",
    "    picker.set_cacher(cacher)\n",
    "    if notify:\n",
    "        notifier = WtMailNotifier(user=EMAIL_HOTMAIL['user'],\n",
    "                                  pwd=EMAIL_HOTMAIL['passwd'],\n",
    "                                  host=EMAIL_HOTMAIL['host'],\n",
    "                                  port=EMAIL_HOTMAIL['port'],\n",
    "                                  isSSL=False)\n",
    "        notifier.add_receiver(addr=\"harveywu@gmail.com\")\n",
    "        picker.set_mail_notifier(notifier)\n",
    "    picker.execute_increment(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"C:/dev/wtdev/hotpicker/hots.json\", \"C:/dev/wtdev/hotpicker/seconds.json\", \"C:/dev/wtdev/hotpicker/marker.json\"]\n",
    "daily_hot_rules(files=files, notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check nearby rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020,1,2)\n",
    "end_date = datetime.date(2022,10,14)\n",
    "nc_df1 = misc.nearby('pg', 1, start_date = start_date, end_date = end_date, roll_rule='-32b',shift_mode=1)\n",
    "#nc_df2 = misc.nearby('pg', 1, start_date = start_date, end_date = end_date, roll_rule='-30b',shift_mode=1)\n",
    "\n",
    "nc_df1 #, nc_df2\n",
    "#nc1_df = misc.nearby('al', 2, start_date = start_date, end_date = end_date, roll_rule='-20b',shift_mode=1)\n",
    "#nc2_df = misc.nearby('al', 2, start_date = start_date, end_date = end_date, roll_rule='-20b',shift_mode=2)\n",
    "#print(nc_df, nc1_df, nc2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2021,1,1)\n",
    "end_date = datetime.date(2022,6,28)\n",
    "\n",
    "#load_fut_by_product('i', 'DCE', start_date ,end_date, freq = 'd')\n",
    "\n",
    "prodcode = 'sc'\n",
    "df1 = dataseries.nearby(prodcode, n = 1, start_date = start_date, end_date = end_date,\n",
    "           roll_rule = '-25b', freq = 'd', shift_mode = 1, \n",
    "           adj_field = 'close', calc_fields = ['open', 'close', 'high', 'low'], \n",
    "           fill_cont = False,\n",
    "          )\n",
    "\n",
    "df2 = misc.nearby(prodcode, n = 1, start_date = start_date, end_date = end_date, roll_rule = '-25b', freq = 'd', shift_mode = 1)\n",
    "\n",
    "print(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is testing for new nearby rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmqlib3.utility.dataseries import *\n",
    "\n",
    "ferrous_products_mkts = ['rb', 'hc', 'i', 'j', 'jm']\n",
    "ferrous_mixed_mkts = ['ru', 'FG', 'ZC', 'SM', \"SF\", 'nr']\n",
    "base_metal_mkts = ['cu', 'al', 'zn', 'pb', 'ni', 'sn', 'ss']\n",
    "precious_metal_mkts = ['au', 'ag']\n",
    "ind_metal_mkts = ferrous_products_mkts + ferrous_mixed_mkts + base_metal_mkts  \n",
    "petro_chem_mkts = ['l', 'pp', 'v', 'TA', 'MA', 'bu', 'sc', 'fu', 'eg', 'eb', 'lu', 'pg', 'PF'] \n",
    "ind_all_mkts = ind_metal_mkts + petro_chem_mkts\n",
    "ags_oil_mkts = ['m', 'RM', 'y', 'p', 'OI', 'a', 'c', 'cs', 'b'] #, 'b']\n",
    "ags_soft_mkts = ['CF', 'SR', 'jd', 'AP', 'sp', 'CJ', 'UR', 'SA', 'lh', 'PK',] # 'CY',] \n",
    "ags_all_mkts = ags_oil_mkts + ags_soft_mkts\n",
    "eq_fut_mkts = ['IF', 'IH', 'IC', 'IM',]\n",
    "bond_fut_mkts = ['T', 'TF', 'TS']\n",
    "fin_all_mkts = eq_fut_mkts + bond_fut_mkts\n",
    "commod_all_mkts = ind_all_mkts + ags_all_mkts + precious_metal_mkts\n",
    "all_markets = commod_all_mkts + fin_all_mkts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_dict = {\n",
    "    'rb': [datetime.date(2009,8,13), datetime.date(2009,8,13), 5000, '-20b'], \n",
    "    'hc': [datetime.date(2014,3,21), datetime.date(2015,12,11), 5000, '-20b'],\n",
    "    'i': [datetime.date(2013,10,18), datetime.date(2014,4,10), 5000, '-20b'],\n",
    "    'j': [datetime.date(2011,4,15), datetime.date(2012,5,7), 5000, '-20b'],\n",
    "    'jm': [datetime.date(2013,3,22), datetime.date(2013,3,22), 5000, '-20b'],\n",
    "    'ru': [datetime.date(2008,10,10), datetime.date(2008,10,10), 5000, '-20b'], \n",
    "    'FG': [datetime.date(2012,12,7), datetime.date(2012,12,7), 5000, '-20b'], \n",
    "    'ZC': [datetime.date(2013,9,26), datetime.date(2013,9,26), 5000, '-20b'],\n",
    "    'SM': [datetime.date(2016,7,26), datetime.date(2016,10,11), 5000, '-20b'], \n",
    "    'SF': [datetime.date(2016,7,27), datetime.date(2017,3,13), 5000, '-20b'],    \n",
    "    'nr': [datetime.date(2019,8,12), datetime.date(2019,8,12), 5000, '-20b'],\n",
    "    'cu': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'], \n",
    "    'al': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'zn': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'pb': [datetime.date(2014,7,25), datetime.date(2014,7,25), 5000, '-20b'],\n",
    "    'ni': [datetime.date(2015,6,17), datetime.date(2015,6,17), 5000, '-20b'], \n",
    "    'sn': [datetime.date(2017,5,2), datetime.date(2017,5,2), 5000, '-20b'],\n",
    "    'ss': [datetime.date(2019,9,25), datetime.date(2020, 1, 6), 5000, '-20b'],\n",
    "    \n",
    "    'l': [datetime.date(2008,1,18), datetime.date(2010,4,14), 5000, '-20b'],\n",
    "    'pp': [datetime.date(2014,2,28), datetime.date(2014,2,28), 5000, '-20b'], \n",
    "    'v': [datetime.date(2009,5,25), datetime.date(2010,8,16), 5000, '-20b'],   \n",
    "    'TA': [datetime.date(2007,7,10), datetime.date(2008,7,10), 5000, '-20b'],\n",
    "    'MA': [datetime.date(2011,10,28), datetime.date(2013,10,22), 5000, '-20b'], \n",
    "    'sc': [datetime.date(2018, 3, 26), datetime.date(2018,8,30), 5000, '-20b'],\n",
    "    'bu': [datetime.date(2015, 1,16), datetime.date(2015,7,1), 5000, '-20b'],\n",
    "    'fu': [datetime.date(2018, 7, 17), datetime.date(2018,10,10), 5000, '-20b'],\n",
    "    'lu': [datetime.date(2020, 10, 9), datetime.date(2020, 10, 9), 5000, '-20b'], \n",
    "    'eb': [datetime.date(2020, 5, 6), datetime.date(2020, 6, 1), 5000, '-20b'],\n",
    "    'eg': [datetime.date(2019, 4, 2), datetime.date(2019, 4, 2), 5000, '-20b'],\n",
    "    'pg': [datetime.date(2020, 9, 7), datetime.date(2020, 9, 7), 5000, '-20b'],\n",
    "    'PF': [datetime.date(2021,1,5), datetime.date(2021,3,1), 5000, '-20b'],\n",
    "        \n",
    "    'a': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'b': [datetime.date(2019,7,1), datetime.date(2019,7,1), 5000, '-20b'],\n",
    "    'm': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'RM': [datetime.date(2012,12,28), datetime.date(2012,12,28), 5000, '-20b'], \n",
    "    'y': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],  \n",
    "    'p':  [datetime.date(2008,1,2), datetime.date(2008,1,2), 4000, '-20b'], \n",
    "    'OI': [datetime.date(2013,2,21), datetime.date(2013,2,21), 5000, '-20b'], \n",
    "    'c': [datetime.date(2008,1,2), datetime.date(2008,1,2), 5000, '-20b'],\n",
    "    'cs': [datetime.date(2014,12,19), datetime.date(2014,12,19), 5000, '-20b'], \n",
    "    \n",
    "    'UR': [datetime.date(2019, 8, 9), datetime.date(2019, 8, 9), 5000, '-20b'],\n",
    "    'SA': [datetime.date(2019,12,6), datetime.date(2019,12,6), 5000, '-20b'],\n",
    "    'CF': [datetime.date(2008,7,14), datetime.date(2008,7,14), 5000, '-20b'], \n",
    "    'CY': [datetime.date(2017, 9, 1), datetime.date(2017, 9, 1), 5000, '-20b'],\n",
    "    'SR': [datetime.date(2008,7,10), datetime.date(2008,7,10), 5000, '-20b'],\n",
    "    'AP': [datetime.date(2017,12,22), datetime.date(2017,12,22), 5000, '-20b'],\n",
    "    'jd': [datetime.date(2013,11,8), datetime.date(2013,11,8), 5000, '-20b'], \n",
    "    'lh': [datetime.date(2021,1,8), datetime.date(2021,1,8), 5000, '-20b'],    \n",
    "    'PK': [datetime.date(2021,2,1), datetime.date(2021,2,1), 5000, '-20b'],\n",
    "    'CJ': [datetime.date(2019,4,30), datetime.date(2019,4,30), 5000, '-20b'],\n",
    "    'rr': [datetime.date(2019, 9, 1), datetime.date(2019, 9, 1), 5000, '-20b'],\n",
    "    'sp': [datetime.date(2018,11,27), datetime.date(2018,11,27), 5000, '-20b'],\n",
    "    \n",
    "    'au': [datetime.date(2010,1,4), datetime.date(2015,1,16), 5000, '-20b'],\n",
    "    'ag': [datetime.date(2012,5,10), datetime.date(2019,6,26), 5000, '-20b'],\n",
    "    'IF': [datetime.date(2010,5,1), datetime.date(2010,5,1), 5000, '-20b'], \n",
    "    'IH': [datetime.date(2015,5,1), datetime.date(2015,5,1), 5000, '-20b'], \n",
    "    'IC': [datetime.date(2015,5,1), datetime.date(2015,5,1), 5000, '-20b'], \n",
    "    'TF': [datetime.date(2019,6,1), datetime.date(2019,6,1), 5000, '-20b'],\n",
    "    'T': [datetime.date(2019,4,1), datetime.date(2019,4,1), 5000, '-20b'], \n",
    "    'TS': [datetime.date(2018, 9, 1), datetime.date(2018, 9, 1), 5000, '-20b'],\n",
    "    'PM': [datetime.date(2013,10,1), datetime.date(2013,10,1), 5000, '-20b'], \n",
    "    'RI': [datetime.date(2013,1,1), datetime.date(2013,1,1), 5000, '-20b'], \n",
    "    'WH': [datetime.date(2014,5,1), datetime.date(2014,5,1), 5000, '-20b'], \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# script to batch generate nearby rolling csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2008,1,1)\n",
    "end_date = datetime.date(2022,7,22)\n",
    "freq = 'd'\n",
    "roll_mode = 0\n",
    "nb_cont = 2\n",
    "\n",
    "#sn need to fix 2019-12\n",
    "# IF IC IH need to roll quarterly and how to roll monthly\n",
    "roll_name = 'nroll'\n",
    "roll_win = 3\n",
    "cont_thres = 50_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "folder = \"C:\\\\dev\\\\pyktrader3\\\\data\\\\carry\"\n",
    "for prodcode in commod_all_mkts: #bond_fut_mkts: #: # petro_chem_mkts\n",
    "    min_thres = 7_500\n",
    "    roll_cutoff = '-20b'\n",
    "    contract_filter = None\n",
    "    if prodcode in ['IF', 'IC', 'IH', 'sc',]:\n",
    "        min_thres = 0.1 * min_thres\n",
    "    elif prodcode in ['j', 'ni', 'sn', 'cu', 'bc', 'lh']:\n",
    "        min_thres = 0.2 * min_thres\n",
    "    elif prodcode in ['ru', 'nr', 'al', 'zn', 'pb', 'jm', 'ss', 'PK', 'b',]:\n",
    "        min_thres = 0.5 * min_thres\n",
    "    elif prodcode in ['SM', 'SF', 'FG', 'i', 'AP', 'eb', ]:\n",
    "        min_thres = 0.8 * min_thres\n",
    "    elif prodcode in ['T', 'TF', 'TS']:\n",
    "        min_thres = 0\n",
    "    if prodcode in ['IF', 'IC', 'IH']:\n",
    "        roll_cutoff = '0b'\n",
    "\n",
    "#     if prodcode in ['j', ]:\n",
    "#         contract_filter = prod_main_cont_filter\n",
    "    roll_kwargs = {'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "                   'contract_filter': contract_filter, 'min_thres': min_thres}\n",
    "    df = load_processed_fut_by_product(prodcode, start_date=start_date, end_date=end_date, freq=freq, **roll_kwargs)\n",
    "    roll_map, daily_cont = rolling_fut_cont(df, nb_cont=nb_cont, cont_thres=cont_thres, roll_mode=roll_mode)\n",
    "    if roll_map.iloc[-1, 1] == None:\n",
    "        roll_map.iat[-1, 1] = misc.default_next_main_contract(roll_map.iloc[-1, 0], start_date, end_date)\n",
    "    flag = roll_map[1].isna()\n",
    "    print(prodcode, roll_map)\n",
    "    roll_map.loc[flag, 1] = roll_map.loc[flag.shift(1).fillna(False), 0].values\n",
    "    file_name = \"%s\\\\%s_%s.csv\" % (folder, prodcode, roll_name) \n",
    "    roll_map.to_csv(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single product rolling testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2010,1,1)\n",
    "end_date = datetime.date(2022,7,15)\n",
    "freq = 'd'\n",
    "roll_mode = 0\n",
    "nb_cont = 2\n",
    "\n",
    "roll_name = 'nroll'\n",
    "roll_win = 3\n",
    "cont_thres = 50_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "\n",
    "prodcode = 'rb'\n",
    "min_thres = 7_500\n",
    "roll_cutoff = '-20b'\n",
    "contract_filter = None\n",
    "\n",
    "roll_kwargs = {'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "               'contract_filter': contract_filter, 'min_thres': min_thres}\n",
    "df = load_processed_fut_by_product(prodcode, start_date=start_date, end_date=end_date, freq=freq, **roll_kwargs)\n",
    "roll_map, daily_cont = rolling_fut_cont(df, nb_cont=nb_cont, cont_thres=cont_thres, roll_mode=roll_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_date = datetime.date(2022,9,22)\n",
    "shift_mode = 1\n",
    "\n",
    "roll_mode = 0\n",
    "roll_name = 'nroll'\n",
    "nb_cont = 2\n",
    "\n",
    "roll_win = 3\n",
    "cont_thres = 50_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "\n",
    "min_thres = 0\n",
    "roll_cutoff = '-5b'\n",
    "contract_filter = None\n",
    "    \n",
    "folder = \"C:\\\\dev\\\\pyktrader3\\\\data\\\\carry\"\n",
    "\n",
    "data_df = pd.DataFrame()\n",
    "for prodcode in ['rb', 'hc', 'i', 'j']: \n",
    "    if prodcode in ['IF', 'IC', 'IH', 'sc',]:\n",
    "        min_thres = 0.1 * min_thres\n",
    "    elif prodcode in ['j', 'ni', 'sn', 'cu', 'bc', 'lh']:\n",
    "        min_thres = 0.2 * min_thres\n",
    "    elif prodcode in ['ru', 'nr', 'al', 'zn', 'pb', 'jm', 'ss', 'PK', 'b',]:\n",
    "        min_thres = 0.5 * min_thres\n",
    "    elif prodcode in ['SM', 'SF', 'FG', 'i', 'AP', 'eb', ]:\n",
    "        min_thres = 0.8 * min_thres\n",
    "    elif prodcode in ['T', 'TF', 'TS']:\n",
    "        min_thres = 0\n",
    "    if prodcode in ['IF', 'IC', 'IH']:\n",
    "        roll_cutoff = '0b'\n",
    "    roll_kwargs = {'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "                   'contract_filter': contract_filter, 'min_thres': min_thres}\n",
    "    \n",
    "    setting = setting_dict[prodcode]\n",
    "    file_name = \"%s\\\\%s_%s.csv\" % (folder, prodcode, roll_name) \n",
    "    roll_map = pd.read_csv(file_name).set_index('date')\n",
    "    nb_df = nearby_series(prodcode, start_date=setting[0], end_date = end_date, shift_mode = shift_mode,\n",
    "                  freq='d', roll_kwargs=roll_kwargs, roll_map = roll_map)\n",
    "    for key in nb_df:\n",
    "        fields = nb_df[key].columns\n",
    "        nb_df[key]['product'] = prodcode\n",
    "        nb_df[key]['code'] = key\n",
    "        data_df = data_df.append(nb_df[key])\n",
    "print(fields)    \n",
    "#     df = pd.concat([nb_df[key] for key in nb_df],axis=1)\n",
    "#     df.to_csv(\"%s\\\\combined_%s_%s.csv\" % (folder, prodcode, roll_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(data_df.reset_index(), index='date', columns = ['product', 'code'], values = list(fields), aggfunc = 'last')\n",
    "df = df.reorder_levels([1, 2, 0], axis=1).sort_index(axis=1)\n",
    "df.columns.rename(['field', 'product', 'code'], inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df.columns[(df.columns.get_level_values(2) == 'close') & (df.columns.get_level_values(1) == 'c0')]].droplevel([1, 2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodcode = 'i'\n",
    "\n",
    "start_date = datetime.date(2014,1,1)\n",
    "end_date = datetime.date(2022,6,30)\n",
    "\n",
    "freq = 'd'\n",
    "shift_mode = 1\n",
    "contract_filter = None # prod_main_cont_exch\n",
    "roll_mode = 0\n",
    "nb_cont = 2\n",
    "\n",
    "roll_win = 3\n",
    "roll_cutoff = '-20b'\n",
    "min_thres = 5_000\n",
    "cont_thres = 40_000\n",
    "cont_ratio = [1.0, 0.0]\n",
    "\n",
    "nb_df= nearby_series(prodcode, start_date=start_date, end_date=end_date, shift_mode=shift_mode,\n",
    "                     nb_cont=nb_cont, cont_thres=cont_thres, roll_mode=roll_mode,freq=freq, \n",
    "                     roll_kwargs={'roll_win': roll_win, 'roll_cutoff': roll_cutoff, 'cont_ratio': cont_ratio,\n",
    "                                  'contract_filter': contract_filter, 'min_thres': min_thres})\n",
    "print(nb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is for backtest metric testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2018, 1, 2)\n",
    "end_date = datetime.date(2022,7,18)\n",
    "shift_mode = 1\n",
    "\n",
    "roll_mode = 0\n",
    "roll_name = 'nroll'\n",
    "nb_cont = 2\n",
    "\n",
    "prodcode = 'rb'\n",
    "\n",
    "roll_kwargs = {'roll_win': 3, 'roll_cutoff': '-5b', 'cont_ratio': [1.0, 0.0],\n",
    "               'contract_filter': None, 'min_thres': 0}\n",
    "\n",
    "folder = \"C:\\\\dev\\\\pyktrader3\\\\data\\\\carry\"\n",
    "file_name = \"%s\\\\%s_%s.csv\" % (folder, prodcode, roll_name) \n",
    "roll_map = pd.read_csv(file_name).set_index('date')\n",
    "\n",
    "nb_df = nearby_series(prodcode, start_date=start_date, end_date = end_date, shift_mode = shift_mode,\n",
    "              freq='d', roll_kwargs=roll_kwargs, roll_map = roll_map)\n",
    "print(nb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = nb_df['c0']\n",
    "\n",
    "xdf['holding'] = (xdf['price_chg'] - xdf['price_chg'].rolling(14).mean()).shift(1).fillna(0)\n",
    "xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsBase(xdf['holding'].to_frame('rb'), xdf['price_chg'].to_frame('rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_pnl = metrics._lagged_portfolio_pnl().to_frame(name='total')\n",
    "portfolio_pnl['Month'] = portfolio_pnl.index.month\n",
    "portfolio_pnl.index = [i.replace(month=1) for i in portfolio_pnl.index]\n",
    "seasonal_pnl = portfolio_pnl.pivot(columns = 'Month', values = 'total').fillna(0.0)\n",
    "print(seasonal_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#seasonal_pnl.plot(x=seasonal_pnl.index.astype(str))\n",
    "seasonal_pnl.set_index(seasonal_pnl.index.astype('str')).plot(rot=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.holdings, metrics.returns\n",
    "# res = metrics.seasonal_pnl()\n",
    "res_df = metrics.lead_lag()\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = res_df['leadlag_sharpes'].loc['fullsample']\n",
    "ax = ts.plot(kind='bar',figsize=(6, 6))\n",
    "new_ticks = np.linspace(-20, 60, 17)\n",
    "ax.set_xticks(np.interp(new_ticks, ts.index, np.arange(ts.size)))\n",
    "ax.set_xticklabels(new_ticks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metrics.lagged_pnl(lags=[1,2,5,10,20])\n",
    "res['cumpnl'].plot()\n",
    "print(res['sharpe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metrics.smoothed_pnl(smooth_hls=[1, 2, 5, 10, 20])\n",
    "res['cumpnl'].plot()\n",
    "print(res['sharpe'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df['holding'].to_frame('al').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2021-01-04').replace(day=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar_aggregation(nb_df, period = 'weekly', how = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2014,1,1)\n",
    "end_date = datetime.date(2022,6,17)\n",
    "\n",
    "nb_df = dataseries.nearby('al', 1, start_date = start_date, end_date = end_date, roll_rule='-30b',shift_mode=1)\n",
    "#nb1_df = dataseries.nearby('sc', 2, start_date = start_date, end_date = end_date, roll_rule='-20b',shift_mode=1)\n",
    "#nb2_df = nearby('al', 2, start_date = start_date, end_date = end_date, roll_rule='-30b',shift_mode=2)\n",
    "print(nb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_fut_by_product('eg', 'DCE', datetime.date(2022,5,20) ,datetime.date(2022,5,20)))\n",
    "#print(load_fut_by_product('sc', 'INE', datetime.date(2022,3,2) ,datetime.date(2022,3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_df[nb1_df['instID'] == nb_df['instID']]\n",
    "#nb_df.close.plot(color='r')\n",
    "\n",
    "#nb1_df.close.plot(color='y')\n",
    "print(nb1_df.close.diff().max(), nb1_df.price_chg.max())\n",
    "#nb_df[['close']].plot()\n",
    "#flag = nb1_df.close.diff()>1.0\n",
    "#nb1_df[flag | flag.shift(-1)]\n",
    "#nb1_df.loc[datetime.date(2018,9,8):datetime.date(2018,9,20):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2011,1,1)\n",
    "end_date = datetime.date(2022, 1, 28)\n",
    "prodcode = 'ZC'\n",
    "roll_rule = '-30b'\n",
    "shift_mode = 1\n",
    "n = 1\n",
    "\n",
    "adj_field = 'close'\n",
    "calc_fields = ['open', 'close', 'high', 'low']\n",
    "contract_filter = [1, 5, 9]\n",
    "\n",
    "exch = misc.prod2exch(prodcode)\n",
    "xdf = load_fut_by_product(prodcode, exch, start_date ,end_date)\n",
    "xdf['expiry'] = xdf['instID'].apply(lambda x: misc.contract_expiry(x, hols = misc.CHN_Holidays))\n",
    "xdf['month'] = xdf['instID'].apply(lambda x: misc.inst2contmth(x)%100)\n",
    "xdf = xdf.sort_values(['instID', 'date'])\n",
    "\n",
    "if shift_mode == 2:\n",
    "    xdf['price_chg'] = np.log(xdf[adj_field]).diff()\n",
    "else:\n",
    "    xdf['price_chg'] = xdf[adj_field].diff()        \n",
    "xdf.loc[xdf['instID']!=xdf['instID'].shift(1), 'price_chg'] = 0\n",
    "if (roll_rule[0] == '-') and (roll_rule[-1] in ['b', 'd']):\n",
    "    xdf['roll_date'] = xdf['expiry'].apply(lambda x: misc.day_shift(x, roll_rule, hols = misc.CHN_Holidays))\n",
    "    xdf = xdf[xdf.date <= xdf['roll_date']]\n",
    "else:\n",
    "    xdf['roll_date'] = xdf['expiry']\n",
    "if contract_filter:\n",
    "    xdf = xdf[xdf.month.isin(contract_filter)]\n",
    "df = pd.pivot_table(xdf, index = 'date', columns = 'expiry', values = 'instID', aggfunc = 'first')\n",
    "df1 = df.apply(lambda x: pd.Series(x.dropna().values), axis=1)\n",
    "df1 = df1.reset_index()\n",
    "\n",
    "col_df = df1[['date', n-1]].rename(columns = {n-1: 'instID'})\n",
    "#if len(col_df[col_df['instID'].isna()])> 0:\n",
    "#    raise ValueError('There are nan values for product=%s, nearby=%s, roll=%s' % (prodcode, str(n), roll_rule))\n",
    "col_df = col_df.fillna(method = 'ffill')\n",
    "out_df = pd.merge(col_df, xdf,left_on = ['date', 'instID'], right_on=['date', 'instID'], how = 'left')\n",
    "\n",
    "if shift_mode > 0:\n",
    "    cum_adj = out_df.loc[::-1, 'price_chg'].cumsum().shift(1).fillna(0)[::-1]\n",
    "    if shift_mode == 2:\n",
    "        adj_price = out_df[adj_field].iloc[-1]/np.exp(cum_adj)\n",
    "        out_df['shift'] = np.log(adj_price) - np.log(out_df[adj_field])\n",
    "    else:\n",
    "        adj_price = out_df[adj_field].iloc[-1] - cum_adj\n",
    "        out_df['shift'] = adj_price - out_df[adj_field]    \n",
    "\n",
    "    for cfield in calc_fields:\n",
    "        if shift_mode == 2:\n",
    "            out_df[cfield] = out_df[cfield] * np.exp(out_df['shift'])\n",
    "        else:\n",
    "            out_df[cfield] = out_df[cfield] + out_df['shift']\n",
    "else:\n",
    "    out_df['shift'] = 0\n",
    "out_df = out_df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_fut_by_product('TA', 'CZCE', start_date ,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_df[out_df.instID.isna()]\n",
    "\n",
    "#out_df.loc[datetime.date(2017,11,20):datetime.date(2017,12,10),:]\n",
    "#out_df.close.plot()\n",
    "print(out_df.close.diff().max(),out_df.price_chg.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_adj = out_df.loc[::-1, 'price_chg'].cumsum().shift(1).fillna(0)[::-1]\n",
    "price_close = out_df['close'].iloc[-1] - price_adj\n",
    "price_shift = price_close - out_df['close']\n",
    "print(price_close, price_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = xdf.sort_values(['instID', 'date'])\n",
    "xdf['chg'] = xdf['close'].diff()\n",
    "flag = xdf['instID']!=xdf['instID'].shift(1)\n",
    "xdf.loc[flag, 'chg'] = 0\n",
    "print(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adf = df.iloc[:, df.columns.get_level_values(0)=='close']\n",
    "nb_df = nearby(adf, roll = 30)\n",
    "print(nb_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypfopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearby(prodcode, n = 1, start_date = None, end_date = None, \n",
    "           roll_rule = '-20b', shift_mode = 0, \n",
    "           adj_field = 'close', calc_fields = ['open', 'close', 'high', 'low'], \n",
    "           contract_filter = None, fill_cont = False,\n",
    "          ):\n",
    "    exch = misc.prod2exch(prodcode)\n",
    "    xdf = load_fut_by_product(prodcode, exch, start_date ,end_date)\n",
    "    xdf['expiry'] = xdf['instID'].apply(lambda x: misc.contract_expiry(x, hols = misc.CHN_Holidays))\n",
    "    xdf['month'] = xdf['instID'].apply(lambda x: misc.inst2contmth(x)%100)\n",
    "    xdf = xdf.sort_values(['instID', 'date'])\n",
    "\n",
    "    if shift_mode == 2:\n",
    "        xdf['price_chg'] = np.log(xdf[adj_field]).diff()\n",
    "    else:\n",
    "        xdf['price_chg'] = xdf[adj_field].diff()        \n",
    "    xdf.loc[xdf['instID']!=xdf['instID'].shift(1), 'price_chg'] = 0\n",
    "    if (roll_rule[0] == '-') and (roll_rule[-1] in ['b', 'd']):\n",
    "        xdf['roll_date'] = xdf['expiry'].apply(lambda x: misc.day_shift(x, roll_rule, hols = misc.CHN_Holidays))\n",
    "        xdf = xdf[xdf.date <= xdf['roll_date']]\n",
    "    else:\n",
    "        xdf['roll_date'] = xdf['expiry']\n",
    "    if contract_filter:\n",
    "        xdf = xdf[xdf.month.isin(contract_filter)]\n",
    "    df = pd.pivot_table(xdf, index = 'date', columns = 'expiry', values = 'instID', aggfunc = 'first')\n",
    "    df1 = df.apply(lambda x: pd.Series(x.dropna().values), axis=1)\n",
    "    df1 = df1.reset_index()\n",
    "    col_df = df1[['date', n-1]].rename(columns = {n-1: 'instID'})\n",
    "    if len(col_df[col_df['instID'].isna()])> 0:\n",
    "        if fill_cont:\n",
    "            col_df = col_df.fillna(method = 'ffill')\n",
    "        else:\n",
    "            raise ValueError('There are nan values for product=%s, nearby=%s, roll=%s' % (prodcode, str(n), roll_rule))\n",
    "    out_df = pd.merge(col_df, xdf,left_on = ['date', 'instID'], right_on=['date', 'instID'], how = 'left')\n",
    "    if shift_mode > 0:\n",
    "        cum_adj = out_df.loc[::-1, 'price_chg'].cumsum().shift(1).fillna(0)[::-1]\n",
    "        if shift_mode == 2:\n",
    "            adj_price = out_df[adj_field].iloc[-1]/np.exp(cum_adj)\n",
    "            out_df['shift'] = np.log(adj_price) - np.log(out_df[adj_field])\n",
    "        else:\n",
    "            adj_price = out_df[adj_field].iloc[-1] - cum_adj\n",
    "            out_df['shift'] = adj_price - out_df[adj_field]    \n",
    "\n",
    "        for cfield in calc_fields:\n",
    "            if shift_mode == 2:\n",
    "                out_df[cfield] = out_df[cfield] * np.exp(out_df['shift'])\n",
    "            else:\n",
    "                out_df[cfield] = out_df[cfield] + out_df['shift']\n",
    "    else:\n",
    "        out_df['shift'] = 0\n",
    "    out_df = out_df.set_index('date')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"C:/dev/wtdev/common/hots.json\", 'r') as infile:\n",
    "    config = json.load(infile)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame.from_records(config['CFFEX']['IF'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
