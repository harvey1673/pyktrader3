{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['PY3_PROD'] = '1'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.system('kinit')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from pycmqlib3.utility import dbaccess, dataseries, misc\n",
    "import pycmqlib3.analytics.data_handler as dh\n",
    "\n",
    "\n",
    "import sys\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(\"C:/dev/pyktrader3/\")\n",
    "sys.path.append(\"C:/dev/wtpy/\")\n",
    "sys.path.append(\"C:/dev/akshare/\")\n",
    "sys.path.append(\"C:/dev/wtdev/\")\n",
    "\n",
    "from pycmqlib3.analytics.tstool import *\n",
    "from pycmqlib3.analytics.btmetrics import *\n",
    "from pycmqlib3.analytics.backtest_utils import *\n",
    "from misc_scripts.fun_factor_update import *\n",
    "from pycmqlib3.strategy.signal_repo import *\n",
    "from bktest.backtest_grid_search import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))\n",
    "lead_lag_config = {\n",
    "    'll_left': -20,\n",
    "    'll_right': 120,\n",
    "    'll_spacing': 5,\n",
    "    'll_sub_win': [(datetime.date(2008, 1, 1), datetime.date(2016, 12, 31)), \n",
    "                   (datetime.date(2017, 1, 1), datetime.date(2022, 12, 31)),],\n",
    "}\n",
    "\n",
    "ll_keys = ['fullsample'] + ['%s:%s' % (sd.strftime('%Y-%b-%d'), ed.strftime('%Y-%b-%d')) for sd, ed in lead_lag_config['ll_sub_win']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# product group and starting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_scripts.update_fut_prices import load_saved_fut\n",
    "tday = datetime.date(2024,11,2)\n",
    "\n",
    "df = load_saved_fut(tday, freq='d')\n",
    "spot_df = load_fun_data(tday)\n",
    "\n",
    "start_date = df.index[0]\n",
    "end_date = tday\n",
    "\n",
    "cdates = pd.date_range(start=start_date, end=tday, freq='D')\n",
    "bdates = pd.bdate_range(start=start_date, end=end_date, freq='C', holidays=misc.CHN_Holidays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdates = [d for d in bdates if d.date() not in [datetime.date(2014,1,2), datetime.date(2014,1,3)]]\n",
    "df = df.reindex(index=bdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset_cont in df.columns.get_level_values(0).unique():    \n",
    "    flag = df[(asset_cont, \"a1505\")].isna()\n",
    "    df.loc[flag, (asset_cont, 'a1505')]= df.loc[flag, (asset_cont, 'close')]            \n",
    "    for traded_price in ['n305', 'n310', 'n315', 'n450']:\n",
    "        flag = df[(asset_cont, traded_price)].isna()\n",
    "        df.loc[flag, (asset_cont, traded_price)]= df.loc[flag, (asset_cont, 'a1505')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_pairs = [('j', 'i'), ('j', 'jm'), ('rb', 'i'), ('hc', 'i'),]\n",
    "beta_ret_dict = {}\n",
    "beta_dict = {}\n",
    "beta_win = 122\n",
    "vwin = 20\n",
    "for trade_asset, index_asset in asset_pairs:\n",
    "    asset_df = df[[(f'{index_asset}c1', 'close'), (f'{trade_asset}c1', 'close')]].copy(deep=True).droplevel([1], axis=1)\n",
    "    asset_df = asset_df.pct_change().dropna()\n",
    "    asset_df.columns = [col[:-2] for col in asset_df.columns]    \n",
    "    for asset in asset_df:\n",
    "        asset_df[f'{asset}_pct'] = asset_df[asset].rolling(5).mean()\n",
    "        asset_df[f'{asset}_vol'] = asset_df[asset].rolling(vwin).std()\n",
    "    asset_df['beta'] = asset_df[f'{index_asset}_pct'].rolling(beta_win).cov(asset_df[f'{trade_asset}_pct'])/asset_df[f'{index_asset}_pct'].rolling(beta_win).var()\n",
    "    key = '_'.join([trade_asset, index_asset])\n",
    "    asset_df['pct_chg'] = asset_df[trade_asset] - asset_df['beta'] * asset_df[index_asset].fillna(0)\n",
    "    asset_df['pct_vol'] = asset_df['pct_chg'].rolling(vwin).std()\n",
    "    asset_df['trade_leg'] = asset_df[f'{trade_asset}_vol']/asset_df['pct_vol']\n",
    "    asset_df['index_leg'] = - asset_df[f'{index_asset}_vol'] / asset_df['pct_vol'] * asset_df['beta']\n",
    "    \n",
    "    beta_ret_dict[key] = asset_df['pct_chg']\n",
    "    beta_dict[key] = asset_df[['beta', 'trade_leg', 'index_leg']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_win = 20\n",
    "product_list = list(set([col[:-2] for col in df.columns.get_level_values(0).unique()]))\n",
    "\n",
    "for asset in product_list:    \n",
    "    if (asset+'c2', 'close') not in df.columns:\n",
    "        print(asset)\n",
    "        continue\n",
    "    spot_df[f'{asset}_ryield'] = ((\n",
    "        np.log(df[(asset+'c1', 'close')]) - np.log(df[(asset+'c2', 'close')]) - \n",
    "        df[(asset+'c1', 'shift')] + df[(asset+'c2', 'shift')])/(\n",
    "        df[(asset+'c2', 'expiry')] - df[(asset+'c1', 'expiry')]).dt.days*365.0 + spot_df['r007_cn'].ffill()/100).dropna()\n",
    "    spot_df[f'{asset}_px'] = df[(asset+'c1', 'close')]\n",
    "    spot_df[f'{asset}_logret'] = np.log(df[(asset+'c1', 'close')]).dropna().diff()\n",
    "    spot_df[f'{asset}_pctchg'] = np.log(df[(asset+'c1', 'close')]).dropna().pct_change()    \n",
    "    spot_df[f'{asset}_logret2'] = np.log(df[(asset+'c2', 'close')]).dropna().diff()\n",
    "    spot_df[f'{asset}_basmom'] =spot_df[f'{asset}_logret'] - spot_df[f'{asset}_logret2']        \n",
    "    spot_df[f'{asset}_pctvol'] = spot_df[f'{asset}_pctchg'].dropna().rolling(vol_win).std()\n",
    "    spot_df[f'{asset}_basmom5'] = spot_df[f'{asset}_basmom'].dropna().rolling(5).sum()\n",
    "    spot_df[f'{asset}_basmom10'] = spot_df[f'{asset}_basmom'].dropna().rolling(10).sum()\n",
    "    spot_df[f'{asset}_basmom20'] = spot_df[f'{asset}_basmom'].dropna().rolling(20).sum()\n",
    "    spot_df[f'{asset}_basmom40'] = spot_df[f'{asset}_basmom'].dropna().rolling(40).sum()\n",
    "    spot_df[f'{asset}_basmom60'] = spot_df[f'{asset}_basmom'].dropna().rolling(60).sum()\n",
    "    spot_df[f'{asset}_basmom100'] = spot_df[f'{asset}_basmom'].dropna().rolling(100).sum()\n",
    "    spot_df[f'{asset}_basmom120'] = spot_df[f'{asset}_basmom'].dropna().rolling(120).sum()\n",
    "    spot_df[f'{asset}_basmom170'] = spot_df[f'{asset}_basmom'].dropna().rolling(170).sum()\n",
    "    spot_df[f'{asset}_basmom180'] = spot_df[f'{asset}_basmom'].dropna().rolling(180).sum()\n",
    "    \n",
    "spot_df['hc_rb_diff'] = np.log(df[('hcc1', 'close')]) - np.log(df[('rbc1', 'close')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmqlib3.strategy.signal_repo import *\n",
    "from misc_scripts.fun_factor_update import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_mkts = [\n",
    "    'rb', 'hc', 'i', 'j', 'jm', 'FG', 'v', 'SM', 'SF', 'SA',\n",
    "    'cu', 'al', 'zn', 'ni', 'pb', 'sn', 'ss', 'si', 'ao', 'au', 'ag',#'bc'\n",
    "    'ru', 'l', 'pp', 'TA', 'MA', 'sc', 'eb', 'eg', 'UR', 'lu', #'bu', 'fu',\n",
    "    'm', 'RM', 'y', 'p', 'OI', 'a', 'c', 'CF', 'jd', 'AP', 'lh', #'cs',\n",
    "]\n",
    "\n",
    "ind_mkts = ['rb', 'hc', 'i', 'j', 'jm', 'FG', 'v', 'SA', 'UR', 'SM', 'SF', \n",
    "    'cu', 'al', 'zn', 'ni', 'pb', 'sn', 'ss', 'ao', 'au', 'ag',#'bc', 'si', \n",
    "    'ru', 'l', 'pp', 'TA', 'MA', 'sc', 'eb', 'eg', 'lu', #'bu', 'fu',\n",
    "]\n",
    "\n",
    "signal_by_func = {\n",
    "    **factors_by_func,\n",
    "    **{ \n",
    "    }\n",
    "}\n",
    "\n",
    "signal_by_spread = {\n",
    "    **factors_by_spread,\n",
    "    **{\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "signal_by_beta_neutral = {\n",
    "    **factors_by_beta_neutral,\n",
    "    **{\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "signal_by_asset = {\n",
    "    **factors_by_asset,\n",
    "    **{\n",
    "        \"ryield_ema\": broad_mkts,\n",
    "        'metal_pbc_ema': ['cu', 'al', 'zn', 'pb', 'ni', 'ss', 'sn', 'ao',\n",
    "                          'rb', 'hc', 'i', 'v', 'FG', 'SA'],\n",
    "        'metal_mom_hlrhys': ['cu', 'al', 'zn', 'pb', 'ni', 'ss', 'sn', 'ao', \n",
    "                             'rb', 'hc', 'i', 'j', 'jm', 'SM', 'SF', 'v', 'FG', 'SA'],\n",
    "        'metal_inv_hlr': ['cu', 'al', 'zn', 'pb', 'ni', 'ss', 'sn', 'ao',\n",
    "                          'rb', 'hc', 'i', 'v', 'FG', 'SA'],\n",
    "        'metal_inv_lyoy_hlr': ['cu', 'al', 'zn', 'pb', 'ni', 'ss', 'sn', 'ao', \n",
    "                               'rb', 'hc', 'i', 'v', 'FG', 'SA'], \n",
    "        \n",
    "        'lme_base_ts_mds': ['cu', 'al', 'zn', 'pb', 'ni', 'sn'],\n",
    "        'lme_base_ts_hlr': ['cu', 'al', 'zn', 'pb', 'ni', 'sn'],\n",
    "        'lme_futbasis_ma': ['cu', 'al', 'zn', 'pb', 'ni', 'sn'],\n",
    "        'base_inv_shfe_ma': ['cu', 'al', 'zn', 'pb', 'ni', 'sn'],\n",
    "        'base_inv_lme_ma': ['cu', 'al', 'zn', 'pb', 'ni', 'sn'],\n",
    "        'base_inv_exch_ma': ['cu', 'al', 'zn', 'pb', 'ni', 'sn'],\n",
    "        'base_phybas_carry_ma': ['cu', 'al', 'zn', 'ni', 'sn', 'pb'],\n",
    "        'base_inv_mds': ['cu', 'al', 'zn', 'ni', 'sn', 'pb', 'ss', 'si', 'ao'],\n",
    "        'base_tc_1y_zs': ['cu', 'pb', 'zn'],\n",
    "        'base_tc_2y_zs': ['cu', 'pb', 'sn'],\n",
    "        'base_cifprem_1y_zs': ['cu', 'al', 'zn', 'ni'],\n",
    "        'base_phybasmom_1m_zs': ['cu', 'al', 'zn', 'ni', 'pb', 'sn'],\n",
    "        'base_phybasmom_1y_zs': ['cu', 'al', 'zn', 'ni', 'pb', 'sn'],\n",
    "    }\n",
    "}\n",
    "\n",
    "signal_by_data = {\n",
    "    **single_factors,\n",
    "    **{\n",
    "        'steel_margin_lvl_fast': ['rb', 'hc', 'i', 'j', 'jm'],\n",
    "        'strip_hsec_lvl_mid': ['rb', 'hc', 'i', 'j', 'jm'],\n",
    "        'io_removal_lvl': ['i'],\n",
    "        'io_removal_lyoy': ['i'],\n",
    "        'io_millinv_lyoy': ['hc', 'i'],\n",
    "        'io_inv_rmv_ratio_1y': ['i'],\n",
    "        'ioarb_px_hlr': ['rb', 'hc', 'i'],\n",
    "        'ioarb_px_hlrhys': ['rb', 'hc', 'i'],\n",
    "        'steel_sinv_lyoy_zs': ['rb', 'hc', 'i', 'FG', 'v'],\n",
    "        'steel_sinv_lyoy_mds': ['rb', 'hc', 'i', 'FG', 'v'],\n",
    "        'rbsales_lyoy_mom_lt': ['rb'],\n",
    "        'rb_sales_inv_ratio_lyoy': ['rb'],\n",
    "        'fef_c1_c2_ratio_or_qtl': ['rb', 'hc', 'j'],\n",
    "        'fef_fly_ratio_or_qtl': ['rb', 'hc', 'j'],\n",
    "        'fef_basmom_or_qtl': ['rb', 'hc'],\n",
    "        'fef_basmom5_or_qtl': ['rb', 'hc'],      \n",
    "        \"const_etf_mom_zsa\": [\"rb\", \"i\", \"j\", \"FG\", \"v\"],\n",
    "        \"const_etf_mom_ewm\": [\"rb\", \"i\", \"j\", \"FG\", \"v\"],\n",
    "        \"prop_etf_mom_dbth_zs\": [\"rb\", \"i\", \"FG\", \"v\"],\n",
    "        \"prop_etf_mom_dbth_qtl\": [\"rb\", \"i\", \"FG\", \"v\"],\n",
    "        \"prop_etf_mom_dbth_qtl2\": [\"rb\", \"i\", \"FG\", \"v\"],  \n",
    "        \n",
    "        \"al_alumina_qtl\": ['al'],\n",
    "        \"al_alumina_yoy_qtl\": ['al'],\n",
    "        \"al_coal_qtl\": ['al'],\n",
    "        \"ni_nis_mom_qtl\": ['ni'],\n",
    "        \"ni_ore_qtl\": ['ni'],\n",
    "        \"sn_conc_spot_hlr\": ['sn'],\n",
    "        'cu_prem_usd_zsa': ['cu'],\n",
    "        'cu_prem_usd_md': ['cu'],\n",
    "        'cu_phybasis_zsa': ['cu'],\n",
    "        'cu_phybasis_hlr': ['cu'],\n",
    "        \"base_etf_mom_zsa\": [\"cu\", \"al\", \"zn\", \"pb\", \"ni\", \"sn\"],\n",
    "        \"base_etf_mom_ewm\": [\"cu\", \"al\", \"zn\", \"pb\", \"ni\", \"sn\"],        \n",
    "    }\n",
    "}\n",
    "\n",
    "feature_setup = {\n",
    "    **signal_store,\n",
    "    **{      \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strategy portfolio config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prem_fact = 25000\n",
    "metal_fact = 8000\n",
    "misc_fact = 12000\n",
    "ferr_fact = 20000\n",
    "base_fact = 20000\n",
    "\n",
    "prem_strats = [\n",
    "    [\"ryield_ema\", 0.082*prem_fact], \n",
    "    [\"ryield_ema_xdemean\", 0.20*prem_fact], \n",
    "    [\"ryield_st_zsa\", 0.016*prem_fact],\n",
    "    [\"ryield_st_zsa_xdemean\", 0.02*prem_fact],\n",
    "    [\"ryield_lt_zsa\", 0.025*prem_fact],\n",
    "    [\"ryield_lt_zsa_xdemean\", 0.045*prem_fact],\n",
    "    \n",
    "    [\"basmom20_ema\", 0.013*prem_fact],\n",
    "    [\"basmom20_ema_xdemean\", 0.032*prem_fact],           \n",
    "    [\"basmom60_ema\", 0.022*prem_fact],\n",
    "    [\"basmom60_ema_xdemean\", 0.027*prem_fact], \n",
    "    [\"basmom120_ema\", 0.02*prem_fact],\n",
    "    [\"basmom120_ema_xdemean\", 0.035*prem_fact],\n",
    "\n",
    "    [\"mom_momma240\", 0.02*prem_fact],\n",
    "    [\"mom_momma240_xdemean\", 0.062*prem_fact],\n",
    "    [\"mom_momma20\", 0.009*prem_fact],\n",
    "    [\"mom_momma20_xdemean\", 0.0105*prem_fact],     \n",
    "    [\"mom_hlr_st\", 0.062*prem_fact],\n",
    "    [\"mom_hlr_st_xdemean\", 0.04*prem_fact], \n",
    "    [\"mom_hlr_lt_xdemean\", 0.014*prem_fact],\n",
    "    [\"mom_hlr_yr_xdemean\", 0.00*prem_fact],   \n",
    "]\n",
    "\n",
    "metal_strats = [\n",
    "    ['metal_pbc_ema', 0.457*metal_fact],\n",
    "    ['metal_pbc_ema_xdemean', 0.315*metal_fact],    \n",
    "    ['metal_mom_hlrhys', 0.316*metal_fact],\n",
    "    ['metal_mom_hlrhys_xdemean', 0.042*metal_fact],\n",
    "    \n",
    "    ['metal_inv_hlr', 0.093*metal_fact],\n",
    "    ['metal_inv_hlr_xdemean', 2.26*metal_fact],\n",
    "#     ['metal_inv_lyoy_hlr', 0],        \n",
    "]\n",
    "\n",
    "misc_strats = [\n",
    "    [\"exch_wnt_hlr\", 0.336*misc_fact],\n",
    "    [\"exch_wnt_hlr_xdemean\", 0.336*misc_fact],\n",
    "    [\"exch_wnt_yoy_hlr\", 0.336*misc_fact],\n",
    "    [\"exch_wnt_yoy_hlr_xdemean\", 0.336*misc_fact],        \n",
    "    [\"leadlag_d_mid\", 0.28*misc_fact],\n",
    "    ['leadlag2_mr_d', 0.47*misc_fact],\n",
    "    ['pair_mr_1y', 1.4*misc_fact],\n",
    "    [\"hc_rb_diff_20\", 0.1*misc_fact],    \n",
    "]\n",
    "\n",
    "ferrous_strats = [\n",
    "    ['io_inv_rmv_ratio_1y', 1.71*ferr_fact],\n",
    "    ['io_removal_lvl', 1.04*ferr_fact],\n",
    "    ['io_removal_lyoy', 0.1*ferr_fact],\n",
    "    ['io_millinv_lyoy', 0.74*ferr_fact],\n",
    "    ['strip_hsec_lvl_mid', 0.05*ferr_fact],\n",
    "    ['steel_margin_lvl_fast', 0.195*ferr_fact],\n",
    "    [\"steel_sinv_lyoy_zs\", 0.2*ferr_fact],\n",
    "    [\"steel_sinv_lyoy_mds\", 0.1*ferr_fact],\n",
    "    ['fef_c1_c2_ratio_or_qtl', 0.07*ferr_fact],    \n",
    "    ['fef_fly_ratio_or_qtl', 0.155*ferr_fact],\n",
    "    ['fef_basmom_or_qtl', 0*ferr_fact],\n",
    "    ['fef_basmom5_or_qtl', 0.39*ferr_fact],\n",
    "    ['fef_c1_c2_ratio_spd_qtl', 0.25*ferr_fact],    \n",
    "    ['fef_basmom5_spd_qtl', 0.51*ferr_fact],\n",
    "    \n",
    "    ['io_pinv31_lvl_zsa', 0*ferr_fact],\n",
    "    ['io_pinv45_lvl_hlr', 0.217*ferr_fact],\n",
    "    ['ioarb_px_hlr', 0.03*ferr_fact],\n",
    "    ['ioarb_px_hlrhys', 0.03*ferr_fact],\n",
    "    \n",
    "    ['ioarb_spd_qtl_1y', 0.62*ferr_fact],\n",
    "    ['const_etf_mom_zsa', 0*ferr_fact],\n",
    "    ['const_etf_mom_ewm', 0.164*ferr_fact],\n",
    "    ['prop_etf_mom_dbth_zs', 0.178*ferr_fact],\n",
    "    ['prop_etf_mom_dbth_qtl', 0.076*ferr_fact],\n",
    "    ['rbsales_lyoy_mom_lt', 0.2*ferr_fact],    \n",
    "    ['rb_sales_inv_ratio_lyoy', 0.2*ferr_fact],\n",
    "    ['rbsales_lyoy_spd_st', 0.5*ferr_fact],\n",
    "    ['rbhc_dmd_mds', 0.3*ferr_fact],\n",
    "    ['rbhc_sinv_mds', 0.2*ferr_fact],        \n",
    "]\n",
    "\n",
    "base_strats = [\n",
    "    ['lme_base_ts_mds', 0.29*base_fact],\n",
    "    ['lme_base_ts_mds_xdemean', 0.24*base_fact],\n",
    "    ['lme_base_ts_hlr', 0*base_fact],\n",
    "    ['lme_base_ts_hlr_xdemean', 0.035*base_fact],\n",
    "    ['lme_futbasis_ma', 0.016*base_fact],\n",
    "    ['lme_futbasis_ma_xdemean', 0.4*base_fact],     \n",
    "    ['base_phybas_carry_ma', 0.354*base_fact],\n",
    "    ['base_phybas_carry_ma_xdemean', 0*base_fact],   \n",
    "    ['base_phybasmom_1m_zs', 0.05*base_fact],\n",
    "    ['base_phybasmom_1m_zs_xdemean', 0.47*base_fact],         \n",
    "    ['base_phybasmom_1y_zs', 0.028*base_fact],\n",
    "    ['base_phybasmom_1y_zs_xdemean', 0*base_fact],          \n",
    "    ['base_cifprem_1y_zs', 0.42*base_fact],\n",
    "    ['base_cifprem_1y_zs_xdemean', 0.006*base_fact],       \n",
    "    ['base_tc_1y_zs', 0.53*base_fact],\n",
    "    ['base_tc_2y_zs', 0.215*base_fact],     \n",
    "    ['base_inv_mds', 0.19*base_fact],\n",
    "    ['base_inv_mds_xdemean', 0.31*base_fact],         \n",
    "    ['base_inv_exch_ma', 0.006*base_fact],\n",
    "    ['base_inv_exch_ma_xdemean', 0.164*base_fact],     \n",
    "#     ['base_inv_shfe_ma', 1.0],\n",
    "#     ['base_inv_shfe_ma_xdemean', 1.0],      \n",
    "    ['base_etf_mom_zsa', 0.2*base_fact],\n",
    "    ['base_etf_mom_ewm', 0.0*base_fact],           \n",
    "    ['al_alumina_qtl', 0.038*base_fact],\n",
    "    ['al_alumina_yoy_qtl', 0.106*base_fact],     \n",
    "    ['al_coal_qtl', 0.176*base_fact],\n",
    "    ['ni_nis_mom_qtl', 0.13*base_fact],      \n",
    "    ['ni_ore_qtl', 0.14*base_fact],\n",
    "    ['sn_conc_spot_hlr', 0.22*base_fact],      \n",
    "]\n",
    "\n",
    "\n",
    "strat_group = prem_strats + metal_strats + misc_strats + ferrous_strats + base_strats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run backtest for a portfolio group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_dict = {}\n",
    "pnl_dict = {}\n",
    "holding_dict = {}\n",
    "signal_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder = \"C:\\\\dev\\\\data\\\\data_cache\\\\\"\n",
    "\n",
    "start_date = datetime.date(2008,1,1)\n",
    "end_date = datetime.date.today()\n",
    "\n",
    "portfolio_map = {\n",
    "    'prod': strat_group,\n",
    "}\n",
    "\n",
    "risk_scaling = 1\n",
    "asset_scaling = False\n",
    "std_win = 20\n",
    "trd_cost = 2e-4\n",
    "\n",
    "pnl_tenors = ['6m', '1y', '2y', '3y', '4y', '5y', '6y', '7y', '8y', '9y', '10y', '12y', '15y']\n",
    "\n",
    "asset_list = [\n",
    "    'rb', 'hc', 'i', 'j', 'jm', 'FG', 'v', 'SM', 'SF', 'SA',\n",
    "    'cu', 'al', 'zn', 'ni', 'pb', 'sn', 'ss', 'ao', 'au', 'ag', #'si', \n",
    "    'ru', 'l', 'pp', 'TA', 'MA', 'sc', 'eb', 'eg', 'UR', 'lu', 'bu', 'fu',\n",
    "    'm', 'RM', 'y', 'p', 'OI', 'a', 'c', 'CF', 'jd', 'AP', 'lh', 'cs', #'bc'\n",
    "]\n",
    "\n",
    "product_list = [asset+'c1' for asset in asset_list]\n",
    "\n",
    "close_prices = df.loc[:, df.columns.get_level_values(0).isin(product_list) &\n",
    "                      (df.columns.get_level_values(1)=='close')].droplevel([1], axis=1).dropna(how='all').ffill()\n",
    "close_prices.columns = [col[:-2] for col in close_prices.columns]\n",
    "close_prices = close_prices[asset_list]\n",
    "vol_df = close_prices.pct_change().rolling(std_win).std()\n",
    "\n",
    "portfolio_name = 'prod'\n",
    "run_key = portfolio_name\n",
    "strat_portfolio = portfolio_map[portfolio_name]\n",
    "\n",
    "pos_sum = pd.DataFrame(0, index=df.index, columns=asset_list)\n",
    "\n",
    "bt_dict[run_key] = {}\n",
    "signal_dict[run_key] = {}\n",
    "pnl_dict[run_key] = {}\n",
    "holding_dict[run_key] = {}\n",
    "\n",
    "agg_signal = pd.DataFrame(index=df.index, columns=asset_list)\n",
    "agg_pnl = pd.DataFrame(index=df.index, columns=asset_list)\n",
    "pnl_by_signal = pd.DataFrame(index=df.index, columns=[signal_name for signal_name, weight in strat_portfolio])\n",
    "port_start = pd.to_datetime('2010-01-01')\n",
    "\n",
    "for signal_name, weight in strat_portfolio:    \n",
    "    print(signal_name)\n",
    "    if signal_name in signal_by_func:\n",
    "        func = signal_by_func[signal_name]['func']\n",
    "        func_args = signal_by_func[signal_name]['args']     \n",
    "        signal_df = func(df, spot_df, **func_args)\n",
    "    elif signal_name in signal_by_spread:\n",
    "        signal_ts = get_funda_signal_from_store(spot_df, signal_name, price_df=df, signal_repo=feature_setup)\n",
    "        signal_df = pd.DataFrame({asset: signal_ts * w for asset, w in signal_by_spread[signal_name]})            \n",
    "    elif signal_name in signal_by_beta_neutral:        \n",
    "        signal_ts = get_funda_signal_from_store(spot_df, signal_name, price_df=df, signal_repo=feature_setup)\n",
    "        signal_df = pd.DataFrame(index=signal_ts.index)        \n",
    "        for trade_asset, index_asset, w in signal_by_beta_neutral[signal_name]:\n",
    "            if trade_asset not in signal_df.columns:\n",
    "                signal_df[trade_asset] = 0\n",
    "            if index_asset not in signal_df.columns:\n",
    "                signal_df[index_asset] = 0\n",
    "            sig_df = pd.concat([\n",
    "                signal_ts.to_frame('signal'),\n",
    "                beta_dict[key]['trade_leg'].to_frame('trade_w'), \n",
    "                beta_dict[key]['index_leg'].to_frame('index_w')], axis=1).ffill()\n",
    "            sig_df[trade_asset] = sig_df['signal'] * sig_df['trade_w']\n",
    "            sig_df[index_asset] = sig_df['signal'] * sig_df['index_w']\n",
    "            signal_df[[trade_asset, index_asset]] += sig_df[[trade_asset, index_asset]]\n",
    "    elif signal_name in signal_by_data:        \n",
    "        signal_ts = get_funda_signal_from_store(spot_df, signal_name, price_df=df, signal_repo=feature_setup)\n",
    "        signal_df = pd.DataFrame({asset: signal_ts for asset in signal_by_data[signal_name] if asset in asset_list})\n",
    "    else:\n",
    "        xs_type = signal_name.split(\"_\")[-1]\n",
    "        if xs_type in ['xdemean', 'xscore', 'xrank',]:\n",
    "            sig_name = \"_\".join(signal_name.split(\"_\")[:-1])\n",
    "        else:\n",
    "            sig_name = signal_name\n",
    "            xs_type = 'ts'\n",
    "        if sig_name in signal_by_asset:\n",
    "            trade_asset = [asset for asset in asset_list if asset in signal_by_asset[sig_name]]\n",
    "            signal_df = pd.DataFrame(index=df.index, columns=trade_asset)\n",
    "            for asset in trade_asset:\n",
    "                signal_df[asset] = get_funda_signal_from_store(spot_df, signal_name, price_df=df, asset=asset, signal_repo=feature_setup)\n",
    "            if xs_type == 'xdemean':\n",
    "                signal_df = xs_demean(signal_df)\n",
    "            elif xs_type == 'xscore':\n",
    "                signal_df = xs_score(signal_df)\n",
    "        else:\n",
    "            print(\"unsupported signal\")\n",
    "\n",
    "    signal_exec_param = signal_execution_config.get(signal_name, {\"win\": \"n305\", \"lag\": 1})\n",
    "    traded_products = [col + 'c1' for col in signal_df.columns]\n",
    "    \n",
    "    if signal_name in signal_store:\n",
    "        _, _, _, _, _, _, _, post_func, _, _ = signal_store[signal_name][1]\n",
    "        last_func = post_func.split('|')[-1]\n",
    "        if 'buf' in last_func:\n",
    "            buffer_size = float(last_func[3:])\n",
    "            signal_df = signal_buffer(signal_df, buffer_size)\n",
    "        elif 'bfc' in last_func:\n",
    "            buffer_size = float(last_func[3:])\n",
    "            signal_df = signal_cost_optim(signal_df, buffer_size, vol_df[signal_df.columns],\n",
    "                                          cost_dict=simple_cost(signal_df.columns, trd_cost=trd_cost),\n",
    "                                          turnover_dict={},\n",
    "                                          power=3)\n",
    "    traded_prices = df.loc[:, df.columns.get_level_values(0).isin(traded_products) &\n",
    "                      (df.columns.get_level_values(1)==signal_exec_param['win'])].droplevel([1], axis=1).dropna(how='all').ffill()\n",
    "    traded_prices.columns = [col[:-2] for col in traded_prices.columns]\n",
    "    traded_prices = traded_prices[signal_df.columns]    \n",
    "    df_pxchg = traded_prices.pct_change()\n",
    "    holding = generate_holding_from_signal(signal_df, vol_df[signal_df.columns], \n",
    "                                           risk_scaling=risk_scaling, \n",
    "                                           asset_scaling=asset_scaling)    \n",
    "    bt_metrics = MetricsBase(holdings=holding[signal_df.columns],\n",
    "                             returns=df_pxchg[signal_df.columns], \n",
    "                             shift_holdings=signal_exec_param[\"lag\"],\n",
    "                             cost_dict=simple_cost(holding.columns, trd_cost=trd_cost)\n",
    "                            )\n",
    "    bt_dict[run_key][signal_name] = bt_metrics\n",
    "    signal_dict[run_key][signal_name] = signal_df\n",
    "    holding_dict[run_key][signal_name] = holding\n",
    "    \n",
    "    pnl_stats = bt_metrics.calculate_pnl_stats(shift=0, tenors=pnl_tenors, perf_metrics=['sharpe', 'std', 'sortino', 'calmar'])\n",
    "    perf_stats = transform_output(pnl_stats)    \n",
    "    \n",
    "    asset_pnl = bt_metrics.calculate_daily_pnl(traded_prices, close_prices[signal_df.columns], mode='ret')\n",
    "    pnl_dict[run_key][signal_name] = asset_pnl\n",
    "    print(f\"\\nsignal={signal_name}\\n\")\n",
    "    display(perf_stats.round(2))\n",
    "    iplot(asset_pnl.cumsum().sum(axis=1).to_frame(\"total\")[port_start:], title=signal_name)\n",
    "    iplot(asset_pnl.cumsum()[port_start:], title=signal_name)    \n",
    "    display(pd.concat([pnl_stats['pnl_per_trade'].to_frame(\"bias\"), pnl_stats['turnover'].to_frame(\"TO\")], axis=1).round(2))\n",
    "    display(pnl_stats['asset_sharpe_stats'].round(2))\n",
    "    \n",
    "    agg_pnl = agg_pnl.add((asset_pnl*weight).reindex_like(agg_pnl), fill_value=0)\n",
    "    pnl_by_signal[signal_name] = (asset_pnl*weight).sum(axis=1)\n",
    "    agg_signal = agg_signal.add((signal_df*weight).reindex_like(agg_signal), fill_value=0)\n",
    "\n",
    "met_list = []\n",
    "for asset in agg_pnl:\n",
    "    sr_ts = calc_perf_by_tenors(agg_pnl[asset], tenors=pnl_tenors, metric='sharpe')\n",
    "    met_list.append(sr_ts.to_frame(asset))\n",
    "    \n",
    "sr_df = pd.concat(met_list, axis=1)\n",
    "\n",
    "port_pnl = agg_pnl.sum(axis=1)\n",
    "met_list = []\n",
    "for metric in ['sharpe', 'std']:\n",
    "    sr_ts = calc_perf_by_tenors(port_pnl, tenors=pnl_tenors, metric=metric)\n",
    "    sr_ts.index=pnl_tenors\n",
    "    met_list.append(sr_ts.to_frame(metric))\n",
    "port_df = pd.concat(met_list, axis=1)\n",
    "\n",
    "display(port_df.round(3))\n",
    "display(sr_df.round(3))    \n",
    "\n",
    "iplot(agg_pnl.sum(axis=1).cumsum().to_frame('portfolio pnl'))\n",
    "iplot(agg_pnl.cumsum(), title=\"portfolio pnl by asset\")\n",
    "\n",
    "# print(port_pnl[-40:])\n",
    "# port_pnl.to_csv(file_folder + \"port_pnl.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prem_strats + metal_strats + misc_strats + ferrous_strats + base_strats\n",
    "\n",
    "prem_strat_names = [elem[0] for elem in prem_strats]\n",
    "metal_strat_names = [elem[0] for elem in metal_strats]\n",
    "misc_strat_names = [elem[0] for elem in misc_strats]\n",
    "ferrous_strat_names = [elem[0] for elem in ferrous_strats]\n",
    "base_strat_names = [elem[0] for elem in base_strats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "data_dict['prem_pnl'] = pnl_by_signal[prem_strat_names].sum(axis=1)\n",
    "data_dict['misc_pnl'] = pnl_by_signal[misc_strat_names].sum(axis=1)\n",
    "data_dict['metal_pnl'] = pnl_by_signal[metal_strat_names].sum(axis=1)\n",
    "data_dict['ferrous_pnl'] = pnl_by_signal[ferrous_strat_names].sum(axis=1)\n",
    "data_dict['base_pnl'] = pnl_by_signal[base_strat_names].sum(axis=1)\n",
    "\n",
    "pnl_df = pd.DataFrame(data_dict)\n",
    "\n",
    "corr_cutoff = '2017-01-01'\n",
    "print(\"std:\\n%s\\n\" % pnl_df[corr_cutoff:].std(axis=0))\n",
    "print(\"std (total) = %s\" % pnl_df[corr_cutoff:].sum(axis=1).std())\n",
    "iplot(pnl_df.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "corr_cutoff = '2017-01-01'\n",
    "print(\"std:\\n%s\\n\" % pnl_by_signal[corr_cutoff:].std(axis=0))\n",
    "print(\"std (total) = %s\" % pnl_by_signal[corr_cutoff:].sum(axis=1).std())\n",
    "iplot(pnl_by_signal.cumsum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_list = []\n",
    "for sig in pnl_df:\n",
    "    sr_ts = calc_perf_by_tenors(pnl_df[sig], tenors=pnl_tenors, metric='sharpe')\n",
    "    met_list.append(sr_ts.to_frame(sig))\n",
    "    \n",
    "sr_df = pd.concat(met_list, axis=1)\n",
    "sr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_w_df = pnl_df.resample('W').sum()\n",
    "corr_df = pnl_w_df[corr_cutoff:].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(corr_df.astype('float'), \n",
    "            #xticklabels=corr_df.columns, \n",
    "            #yticklabels=corr_df.columns, \n",
    "            #vmin=-1, vmax=1, \n",
    "            cmap='coolwarm',\n",
    "            linewidth=.2,\n",
    "            annot=True,\n",
    "            ax=ax\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_df = pnl_by_signal.copy()\n",
    "pnl_df['exch_wnt'] = pnl_df[[col for col in pnl_df if 'exch_wnt' in col]].sum(axis=1)\n",
    "pnl_df = pnl_df[['exch_wnt', 'leadlag_d_mid', 'leadlag2_mr_d', 'pair_mr_1y', 'hc_rb_diff_20']]\n",
    "# pnl_df['carry'] = pnl_df[['ryield_ema', 'ryield_ema_xdemean']].sum(axis=1)\n",
    "# pnl_df['carrymom'] = pnl_df[[\"ryield_st_zsa\", \"ryield_st_zsa_xdemean\", \"ryield_lt_zsa\", \"ryield_lt_zsa_xdemean\", \"basmom20_ema\", \"basmom20_ema_xdemean\"]].sum(axis=1)\n",
    "# pnl_df['basmom'] = pnl_df[[\"basmom60_ema\", \"basmom60_ema_xdemean\", \"basmom120_ema\", \"basmom120_ema_xdemean\"]].sum(axis=1)\n",
    "# pnl_df['metal_pbc'] = pnl_df[['metal_pbc_ema', 'metal_pbc_ema_xdemean']].sum(axis=1)\n",
    "# pnl_df['metal_mom'] = pnl_df[['metal_mom_hlrhys', 'metal_mom_hlrhys_xdemean']].sum(axis=1)\n",
    "#pnl_df = pnl_df[['carry', 'carrymom', 'basmom', 'metal_pbc', 'metal_mom', 'leadlag_d_mid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypfopt\n",
    "from pypfopt import plotting\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import expected_returns\n",
    "#   \n",
    "#pnl_df = pnl_df.copy()\n",
    "dpnl = pnl_df[[col for col in pnl_df.columns]]['2017-01-01':]\n",
    "\n",
    "if 'combo' in dpnl.columns:\n",
    "    dpnl = dpnl.drop(columns=['combo'])\n",
    "dpnl = dpnl.fillna(0)\n",
    "\n",
    "strat_std = dpnl.std()\n",
    "\n",
    "dpnl = dpnl/dpnl.std()\n",
    "\n",
    "#risk_models.sample_cov(dpnl, returns_data=True, frequency=244)\n",
    "\n",
    "max_sharpe = False\n",
    "\n",
    "if max_sharpe:\n",
    "    mu = expected_returns.mean_historical_return(dpnl, returns_data=True, frequency=244, compounding=False)\n",
    "else:\n",
    "    mu = None\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(dpnl, returns_data=True, frequency=244).ledoit_wolf()\n",
    "ef = EfficientFrontier(mu, S, weight_bounds= (0, 1)) \n",
    "\n",
    "fact_idx = {}\n",
    "for fact in dpnl.columns:\n",
    "    fact_idx[fact] = ef.tickers.index(fact)\n",
    "\n",
    "#ef.add_constraint(lambda w: w[fact_idx['ryield_ema_ts']] + w[fact_idx['ryield_ema_xdemean']] >= 0.3)\n",
    "#ef.add_constraint(lambda w: w[fact_idx['ryield_ema_ts']] + w[fact_idx['ryield_ema_xdemean']] <= 0.4)\n",
    "#ef.add_constraint(lambda w: w[fact_idx['ryield_ema_ts']] + w[fact_idx['ryield_ema_xdemean']] >= 0.3)\n",
    "# ef.add_constraint(lambda w: w[fact_idx['tsmom']] + w[fact_idx['macro2']] <= 0.24)\n",
    "\n",
    "#ef = EfficientFrontier(mu, S, weight_bounds=(0,1))\n",
    "if max_sharpe:\n",
    "    port_weights = ef.max_sharpe()\n",
    "else:\n",
    "    port_weights = ef.min_volatility()\n",
    "\n",
    "#port_weights = ef.clean_weights()\n",
    "port_weights = pd.Series(port_weights)\n",
    "print(\"port_weights=\\n%s\\n\" % port_weights)\n",
    "final_weights = port_weights.div(strat_std)\n",
    "print(\"final_weights=\\n%s\\n\" % final_weights)\n",
    "# mu = expected_returns.mean_historical_return(df)\n",
    "# S = risk_models.sample_cov(df)\n",
    "\n",
    "# # Optimize for maximal Sharpe ratio\n",
    "# ef = EfficientFrontier(mu, S)\n",
    "# weights = ef.max_sharpe()\n",
    "# ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "port_data = {'empirics': bt_empirics, 'scen_stats': scen_stats, 'scen_names': scen_names, 'holdings': holdings}\n",
    "\n",
    "out_file = open('port_data_test.pkl','wb')\n",
    "\n",
    "pickle.dump(port_data, out_file)\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pnl_stats = bt_empirics[run_key].calculate_pnl_stats(shift=0, tenors=pnl_tenors, perf_metrics=['sharpe', 'std', 'sortino', 'calmar'])\n",
    "\n",
    "#pnl_stats['asset_sharpe_stats']\n",
    "\n",
    "for asset in port_stats['asset_cumpnl'].columns:\n",
    "    port_stats['asset_cumpnl'][asset]['2017-01-01':].plot(title=asset)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sum[product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stats = bt_met.calculate_pnl_stats(shift=0, tenors=pnl_tenors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = bt_empirics['hot_elite'].calculate_pnl_stats(shift=0, tenors=pnl_tenors)['portfolio_cumpnl']\n",
    "ts2 = bt_empirics['hot_test'].calculate_pnl_stats(shift=0, tenors=pnl_tenors)['portfolio_cumpnl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# holding and std for strategy group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder = \"C:\\\\dev\\\\data\\\\data_cache\\\\\"\n",
    "\n",
    "#port_stats['portfolio_cumpnl'].to_csv(file_folder + \"port_pnl_est.csv\")\n",
    "\n",
    "print(bt_met.holdings)\n",
    "\n",
    "print(port_stats['portfolio_pnl'].resample('M').sum()[-60:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenors = ['1y', '2y', '3y', '5y', '7y', '9y', '11y']\n",
    "data_list = []\n",
    "run_key = 'hot_funda'\n",
    "for scen_name, scen, pl_stat in zip(scen_names[run_key], scenarios, scen_stats[run_key]):\n",
    "    weight = scen[2]\n",
    "    data = [scen_name, weight] + [pl_stat['std'].loc[f'std_{ten}'] for ten in tenors] + [pl_stat['sharpe'].loc[f'sharpe_{ten}'] for ten in tenors]\n",
    "    data_list.append(data)\n",
    "    \n",
    "data_df = pd.DataFrame(data_list, columns=['strat_name', 'weight'] + [f'std_{ten}' for ten in tenors] + [f'sharpe_{ten}' for ten in tenors])\n",
    "data_df = data_df.set_index('strat_name')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_excel(\"port_perf_check.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asset level cum pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_stats = scen_stats[0]\n",
    "plot_stats = pnl_stats\n",
    "asset_pnl = plot_stats['asset_cumpnl']\n",
    "asset_stats = plot_stats['asset_sharpe_stats']\n",
    "plot_start = pd.to_datetime('2020-01-01')\n",
    "\n",
    "rows = math.ceil(len(product_list)/2)\n",
    "fig, ax = plt.subplots(rows, 2, figsize=(16, 150))\n",
    "\n",
    "for i, col in enumerate(asset_pnl.columns):\n",
    "    row_id = i//2\n",
    "    col_id = i % 2\n",
    "    asset_pnl[col][plot_start:].plot(ax = ax[row_id, col_id], title = col)\n",
    "\n",
    "print(asset_stats[product_list])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smoothed pnl and lagged pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bt_metrics = scen_metrics[2]\n",
    "smoothed = bt_metrics.smoothed_pnl(smooth_hls=[1, 5, 10, 20, 30, 60, 75, 80])\n",
    "smoothed['cumpnl'].plot(figsize=(10,10))\n",
    "print('smoothed PNL\\n', smoothed['sharpe'])\n",
    "plt.show()\n",
    "\n",
    "lagged = bt_metrics.lagged_pnl(lags=[1, 5, 10, 20, 30, 60, 75, 80])\n",
    "lagged['cumpnl'].plot()\n",
    "print('lagged PNL\\n', lagged['sharpe'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scenario PNL and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_start = pd.to_datetime('2014-01-01')\n",
    "df_list = []\n",
    "hot_key = 'hot_test'\n",
    "for scen_name, scen_stat in zip(scen_names[hot_key], scen_stats[hot_key]):\n",
    "    scen_stat['portfolio_cumpnl'][scen_start:].plot(title=scen_name)\n",
    "    plt.show()\n",
    "    ts = scen_stat['portfolio_pnl'][scen_start:]\n",
    "    ts.name = scen_name\n",
    "    df_list.append(ts)\n",
    "dpnl_df = pd.concat(df_list, axis=1, join='outer').fillna(0)\n",
    "dpnl_df.columns = scen_names[hot_key]\n",
    "scen_corr = dpnl_df.corr()\n",
    "\n",
    "# print(scen_corr)\n",
    "scen_corr.to_csv(file_folder + \"port_corr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some test for backtest code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_args = run_args\n",
    "product_list = input_args['product_list']\n",
    "vol_win = input_args['std_win']\n",
    "total_risk = input_args.get('total_risk', 5000000.0)\n",
    "shift_mode = input_args.get('shift_mode', 1)\n",
    "asset_scaling = input_args.get('asset_scaling', False)\n",
    "exec_mode = input_args.get('exec_mode', 'open')\n",
    "signal_df = generate_signal(df, input_args)\n",
    "\n",
    "start_date = input_args.get('start_date', None)\n",
    "end_date = input_args.get('end_date', None)\n",
    "\n",
    "if start_date:\n",
    "    signal_df = signal_df[signal_df.index >= pd.to_datetime(start_date)]\n",
    "if end_date:\n",
    "    signal_df = signal_df[signal_df.index <= pd.to_datetime(end_date)]\n",
    "\n",
    "if shift_mode == 1:\n",
    "    vol_df = get_asset_vols(df, product_list, vol_win=vol_win, vol_type='atr')\n",
    "elif shift_mode == 2:\n",
    "    vol_df = get_asset_vols(df, product_list, vol_win=vol_win, vol_type='lret')\n",
    "else:\n",
    "    vol_df = get_asset_vols(df, product_list, vol_win=vol_win, vol_type='close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding = generate_holding_from_signal(signal_df, vol_df,\n",
    "                                       risk_scaling=total_risk,\n",
    "                                       asset_scaling=asset_scaling)\n",
    "holding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch run backtest for multiple factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bktest.backtest_grid_search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, error_list = load_hist_data(\n",
    "    start_date=datetime.date(2010,1,1),\n",
    "    end_date=datetime.date(2022,1,20),\n",
    "    sim_markets=commod_all_mkts,\n",
    "    freq='d'\n",
    ")\n",
    "\n",
    "if len(error_list) > 0:\n",
    "    print(error_list)\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_d = datetime.date(2012,1,1)\n",
    "end_d = datetime.date(2020,1,1)\n",
    "product_list = ['rb', 'hc', 'i', 'j', 'jm', 'ru', 'FG', 'cu', 'al', 'zn', 'pb', 'sn', \\\n",
    "                'l', 'pp', 'v', 'TA', 'sc', 'm', 'RM', 'y', 'p', 'OI', 'a', 'c', 'CF', 'jd', \\\n",
    "                'AP', 'SM', 'eb', 'eg', 'UR', 'ss', 'lu', 'lh', 'ni',]\n",
    "\n",
    "sim_group = [\n",
    "    ('xscarry-rank', 'basmomema'), ('xscarry-rank_cutoff', 'basmomema'), ('xscarry-demedian', 'basmomema'),\n",
    "    ('xscarry-rank', 'basmomqtl'), ('xscarry-rank_cutoff', 'basmomqtl'), ('xscarry-demedian', 'basmomqtl'),\n",
    "]\n",
    "\n",
    "index_list = range(10, 260, 10)\n",
    "column_list = [10, 20, 40, 61, 80, 100, 122, 244]\n",
    "\n",
    "bt_metric_dict = {}\n",
    "pnl_stats_dict = {}\n",
    "for sim_type, signal_name in sim_group:\n",
    "    print(f\"processing {sim_type} - {signal_name}\")\n",
    "    metric_dict, stat_dict = run_grid_btest(df, start_d, end_d, \n",
    "                                            sim_type, signal_name,\n",
    "                                            index_list=index_list,\n",
    "                                            column_list=column_list,\n",
    "                                            product_list=product_list,\n",
    "                                            pnl_tenors=True,\n",
    "                                            exp_mean=False)\n",
    "    bt_metric_dict[(sim_type, signal_name)] = metric_dict\n",
    "    pnl_stats_dict[(sim_type, signal_name)] = stat_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch run sample code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bktest.backtest_grid_search import *\n",
    "\n",
    "xdf, error_list = load_hist_data(\n",
    "    start_date=datetime.date(2010, 1, 1),\n",
    "    end_date=datetime.date(2020, 1, 1),\n",
    "    sim_markets=all_markets,\n",
    "    freq='d'\n",
    ")\n",
    "\n",
    "\n",
    "group_keys=['all']\n",
    "\n",
    "sim_group=[\n",
    "    ('xsmom-demedian', 'momnma'),\n",
    "    ('xsmom-demedian', 'macdnma'),\n",
    "    # ('xscarry-rank', 'ryieldnma'),\n",
    "    # ('xscarry-rank_cutoff', 'ryieldnma'),\n",
    "    # ('xscarry-rank', 'basmomnma'),\n",
    "    # ('xscarry-rank_cutoff', 'basmomnma'),\n",
    "    # ('xscarry-rank', 'ryieldsma'),\n",
    "    # ('xscarry-rank_cutoff', 'ryieldsma'),\n",
    "]\n",
    "\n",
    "bt_metric_dict, pnl_stats_dict = run_xs_product(xdf, group_keys, sim_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.719px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
