{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['PY3_PROD'] = '1'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.system('kinit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101562ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib\n",
    "from pycmqlib3.utility import dbaccess, dataseries, misc\n",
    "from pycmqlib3.analytics.tstool import *\n",
    "from pycmqlib3.analytics.btmetrics import *\n",
    "from pycmqlib3.analytics.backtest_utils import *\n",
    "from pycmqlib3.strategy.signal_repo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 8)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10cdbe-874b-42fe-9a62-113afda43a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0f400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from misc_scripts.update_fut_prices import load_saved_fut\n",
    "tday = datetime.date(2025, 5, 16)\n",
    "\n",
    "df = load_saved_fut(tday, freq='d')\n",
    "#df = load_cnc_fut(tday, type='cnc')\n",
    "\n",
    "start_date = df.index[0]\n",
    "end_date = tday\n",
    "\n",
    "cdates = pd.date_range(start=start_date, end=tday, freq='D')\n",
    "bdates = pd.bdate_range(start=start_date, end=end_date, freq='C', holidays=misc.CHN_Holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092411dd-8ea3-40d5-8a4b-fa1126a33f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb26f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmqlib3.utility.misc import day_shift, CHN_Holidays, prod2exch, is_workday, \\\n",
    "    nearby, contract_expiry, inst2contmth\n",
    "\n",
    "spot_df = load_fun_data(tday)\n",
    "spot_df['hc_rb_diff'] = np.log(df[('hcc1', 'close')]) - np.log(df[('rbc1', 'close')])    \n",
    "spot_df['io_ctd_spot'] = io_ctd_basis(spot_df, df[('ic1', 'expiry')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d06a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_dict = {}\n",
    "spot_dict['cu_base_phybas'] = spot_df['cu_smm_phybasis']\n",
    "spot_dict['al_base_phybas'] = spot_df['al_smm0_phybasis']\n",
    "spot_dict['zn_base_phybas'] = spot_df['zn_smm0_sh_phybasis']\n",
    "spot_dict['pb_base_phybas'] = spot_df['pb_smm1_sh_phybasis']\n",
    "spot_dict['ni_base_phybas'] = spot_df['ni_smm1_jc_phybasis']\n",
    "spot_dict['sn_base_phybas'] = spot_df['sn_smm1_sh_phybasis']\n",
    "spot_dict['ss_base_phybas'] = spot_df[\"ss_304_wuxi_phybasis\"]\n",
    "spot_dict['cu_tc'] = spot_df['cu_mine_tc']\n",
    "spot_dict['zn_tc'] = spot_df['zn_50conc_tc_henan']\n",
    "spot_dict['pb_tc'] = spot_df['pb_50conc_tc_neimeng']\n",
    "spot_dict['sn_tc'] = spot_df['sn_40conc_tc_yunnan']\n",
    "\n",
    "metal_inv_map = {\n",
    "    'cu': \"cu_inv_social_dom\",\n",
    "    'al': 'al_inv_social_all',\n",
    "    'zn': \"zn_inv_social_all\",\n",
    "    'ni': \"ni_inv27_all\",\n",
    "    'pb': 'pb_inv_social_all',\n",
    "    'sn': 'sn_inv_social_all',\n",
    "    'si': 'si_inv_social_all',\n",
    "    'ao': 'bauxite_inv_az_ports',\n",
    "    'ss': \"ss_inv_social_300\",\n",
    "    'rb': 'rebar_inv_social',\n",
    "    'hc': 'hrc_inv_social',\n",
    "    'j': \"coke_inv_ports_tj\",\n",
    "    'jm': \"ckc_inv_cokery\",\n",
    "    'v': \"v_inv_social\",\n",
    "    'i': 'io_inv_45ports',\n",
    "    'SM': 'sm_inv_mill',\n",
    "    'SF': 'sf_inv_mill',\n",
    "    'FG': \"fg_inv_mill\",\n",
    "    'SA': 'sa_inv_mill_all',\n",
    "}\n",
    "for asset in metal_inv_map:\n",
    "    spot_dict[f'{asset}_sinv'] = spot_df[metal_inv_map[asset]]\n",
    "    \n",
    "spot_dict[\"zn_scrap_sh_mid\"] = (spot_df[\"zn_scrap_sh_low\"] + spot_df[\"zn_scrap_sh_high\"])/2\n",
    "spot_dict[\"al_scrap_shredded_sh_mid\"] = (spot_df[\"al_scrap_shredded_sh_low\"] + spot_df[\"al_scrap_shredded_sh_high\"])/2\n",
    "spot_dict['rebar_total_stockdays'] = (spot_df['rebar_inv_social']).dropna()/spot_df['rebar_app_dmd'].dropna().rolling(52).mean()*7\n",
    "spot_dict['hrc_total_stockdays'] = (spot_df['hrc_inv_social']).dropna()/spot_df['hrc_app_dmd'].dropna().rolling(52).mean()*7    \n",
    "\n",
    "fef_list = []\n",
    "for nb in [2, 3, 4]:\n",
    "    fef_nb = nearby('FEF', n=nb,\n",
    "                    start_date=max(start_date.date(), datetime.date(2016, 1, 1)),\n",
    "                    end_date=tday,\n",
    "                    roll_rule='-3b', freq='d', shift_mode=2, roll_col='settle')\n",
    "    fef_nb.loc[fef_nb['settle'] <= 0, 'settle'] = np.nan\n",
    "    fef_nb.loc[fef_nb['close'] <= 0, 'close'] = np.nan\n",
    "    fef_list.append(fef_nb['settle'].to_frame(f'FEFc{nb-1}'))\n",
    "    fef_list.append(fef_nb['close'].to_frame(f'FEFc{nb-1}_close'))\n",
    "    fef_list.append(fef_nb['shift'].to_frame(f'FEFc{nb-1}_shift'))\n",
    "fef_data = pd.concat(fef_list, axis=1)\n",
    "fef_data.index = pd.to_datetime(fef_data.index)\n",
    "\n",
    "for col in fef_data.columns:\n",
    "    spot_dict[col] = fef_data[col]\n",
    "\n",
    "spot_dict['hc_rb_diff'] = np.log(df[('hcc1', 'close')]) - np.log(df[('rbc1', 'close')])    \n",
    "spot_dict['io_ctd_spot'] = io_ctd_basis(spot_df, df[('ic1', 'expiry')])\n",
    "\n",
    "#product_list = df.\n",
    "metal_pbc = {\n",
    "    \"cu\": \"cu_smm1_spot\",\n",
    "    \"al\": \"al_smm0_spot\",\n",
    "    \"zn\": \"zn_smm0_spot\",\n",
    "    \"pb\": \"pb_smm1_spot\",\n",
    "    \"sn\": \"sn_smm1_spot\",\n",
    "    \"ni\": \"ni_smm1_spot\",\n",
    "    \"ss\": \"ss_304_gross_wuxi\",\n",
    "    \"ao\": \"alumina_spot_qd\",\n",
    "    \"si\": \"si_553_spot_smm\",\n",
    "    \"rb\": \"rebar_sh\",\n",
    "    \"hc\": \"hrc_sh\",\n",
    "    \"i\": \"io_ctd_spot\",\n",
    "    \"j\": \"coke_sub_a_rz\",\n",
    "    #\"jm\": \"ckc_a10v24s08_lvliang\", #\"ckc_a10v24s10_ts\", \n",
    "    \"jm\": \"ckc_outstock_ganqimaodu\", #\"ckc_a10v24s08_lvliang\",\n",
    "    \"FG\": \"fg_5mm_shahe\",\n",
    "    #\"SM\": \"sm_65s17_neimeng\",\n",
    "    \"SM\": \"sm_65s17_tj\",\n",
    "    #\"SF\": \"sf_72_ningxia\",\n",
    "    \"SF\": \"sf_72_neimeng\",\n",
    "    \n",
    "    \"v\": \"pvc_cac2_east\",\n",
    "    #\"SA\": \"sa_heavy_east\",\n",
    "    \"SA\": \"sa_heavy_shahe\",\n",
    "    \"au\": \"au_td_sge\",\n",
    "    \"ag\": \"ag_td_sge\",\n",
    "        \n",
    "    \"MA\": \"ma_spot_jiangsu\",\n",
    "    \"TA\": \"pta_east_spot\",\n",
    "    \"eg\": \"eg_east_spot\",\n",
    "    \"PF\": \"pf_fujian_spot\",\n",
    "    \"l\": \"l_7042_tj\",\n",
    "    \"pp\": \"pp_100ppi_spot\",\n",
    "    \"eb\": \"eb_east_spot\",\n",
    "    'bu': \"bu_heavy_shandong\",\n",
    "    \"pg\": \"pg_jincheng_shandong\",\n",
    "    'ru': \"ru_scrwf_kunming\",\n",
    "    'fu': \"fo_180cst_xiamen\",\n",
    "}\n",
    "\n",
    "vol_win = 20\n",
    "product_list = list(set([col[:-2] for col in df.columns.get_level_values(0).unique()]))\n",
    "\n",
    "for asset in product_list:    \n",
    "    spot_dict[f'{asset}_px'] = df[(asset+'c1', 'close')]\n",
    "    spot_dict[f'{asset}_logret'] = np.log(df[(asset+'c1', 'close')]).dropna().diff()\n",
    "    spot_dict[f'{asset}_pctchg'] = np.log(df[(asset+'c1', 'close')]).dropna().pct_change()        \n",
    "    if (asset+'c2', 'close') not in df.columns:\n",
    "        print(asset)\n",
    "        continue\n",
    "    spot_dict[f'{asset}_ryield'] = (np.log(df[(asset+'c1', 'close')]) - np.log(df[(asset+'c2', 'close')]) - \n",
    "                                  df[(asset+'c1', 'shift')] + df[(asset+'c2', 'shift')])/(df[(asset+'c2', 'expiry')] - df[(asset+'c1', 'expiry')]).dt.days*365.0 + spot_df['r007_cn'].dropna().ewm(5).mean()/100\n",
    "    spot_dict[f'{asset}_logret2'] = np.log(df[(asset+'c2', 'close')]).dropna().diff()\n",
    "    spot_dict[f'{asset}_basmom'] =spot_dict[f'{asset}_logret'] - spot_dict[f'{asset}_logret2']        \n",
    "    spot_dict[f'{asset}_pctvol'] = spot_dict[f'{asset}_pctchg'].dropna().rolling(vol_win).std()\n",
    "    spot_dict[f'{asset}_basmom5'] = spot_dict[f'{asset}_basmom'].dropna().rolling(5).sum()\n",
    "    spot_dict[f'{asset}_basmom10'] = spot_dict[f'{asset}_basmom'].dropna().rolling(10).sum()\n",
    "    spot_dict[f'{asset}_basmom20'] = spot_dict[f'{asset}_basmom'].dropna().rolling(20).sum()\n",
    "    spot_dict[f'{asset}_basmom60'] = spot_dict[f'{asset}_basmom'].dropna().rolling(60).sum()\n",
    "    if asset in metal_pbc:\n",
    "        asset_feature = metal_pbc[asset]\n",
    "        spot_dict[f'{asset}_c1'] = df[(asset+'c1', 'close')] / np.exp(df[(asset+'c1', 'shift')])\n",
    "        spot_dict[f'{asset}_expiry'] = pd.to_datetime(df[(asset+'c1', 'expiry')])\n",
    "        tmp_df = pd.concat([spot_df[asset_feature].dropna(), \n",
    "                            spot_dict[f'{asset}_c1'].dropna().to_frame(f'{asset}_c1'),\n",
    "                            spot_dict[f'{asset}_expiry'].dropna().to_frame(f'{asset}_expiry'),                            \n",
    "                            spot_df['r007_cn'].dropna()\n",
    "                           ], axis=1)\n",
    "        tmp_df['date'] = pd.to_datetime(tmp_df.index)\n",
    "        tmp_df['r007_cn'] = tmp_df['r007_cn'].ffill().ewm(5).mean()/100\n",
    "        #tmp_df['r007_cn'] = tmp_df['shibor_1m'].ffill()/100\n",
    "        spot_dict[f'{asset}_phycarry'] = (np.log(tmp_df[asset_feature]) - np.log(tmp_df[f'{asset}_c1'])) / \\\n",
    "                                           (tmp_df[f'{asset}_expiry'] - tmp_df['date']).dt.days * 365 + tmp_df['r007_cn']\n",
    "\n",
    "keys = [key for key in spot_df.columns if key not in spot_dict]\n",
    "spot_df = pd.concat([spot_df[keys], pd.DataFrame(spot_dict)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acad499",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_win=20\n",
    "pnl_tenors = ['6m', '1y', '2y', '3y', '4y', '5y', '6y', '7y', '8y', '9y', '10y']\n",
    "insample = \"2026-01-01\"\n",
    "\n",
    "empiric_assets = [\n",
    "    'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF',\n",
    "    #'SM', 'SF',\n",
    "    \"UR\", \"ru\", 'si', 'lc', 'ao', #\"PX\", \n",
    "    #\"AP\", \"CJ\",\n",
    "    #'rb', 'hc', \n",
    "    #'jm', \n",
    "    #'i',  'j', \n",
    "    \n",
    "    #'cu', 'al', 'zn', 'ni', 'sn', 'pb', \n",
    "]\n",
    "\n",
    "traded_price = 'n305'\n",
    "df_pxchg = pd.DataFrame(index=df.index)\n",
    "\n",
    "for asset in empiric_assets:\n",
    "    if '_' in asset:\n",
    "        df_pxchg[asset] = beta_ret_dict[asset].dropna()[:insample]\n",
    "    elif '-' in asset:\n",
    "        for sub_asset in asset.split('-'):\n",
    "            if sub_asset not in empiric_assets:\n",
    "                df_pxchg[sub_asset] = df[(sub_asset+'c1', traded_price)].dropna().pct_change()[:insample]                 \n",
    "    else:\n",
    "        if asset in [\"T\", \"TF\", \"TS\", \"TL\", \"IF\", \"IH\", \"IC\", \"IM\"]:\n",
    "            if traded_price in ['n305', 'n310', 'n315', 'n450', 'a1505', 'a1510', 'a1515']:\n",
    "                ts_px = df[(asset+'c1', 'a1535')]\n",
    "            else:\n",
    "                ts_px = df[(asset+'c1', traded_price)]\n",
    "            flag = ts_px.isna()\n",
    "            ts_px.loc[flag] = df[(asset+'c1', 'd_twap')].loc[flag]\n",
    "        else:\n",
    "            ts_px = df[(asset+'c1', traded_price)]\n",
    "            if traded_price in ['n305', 'n310', 'n315', 'n450']:\n",
    "                flag = ts_px.isna()\n",
    "                ts_px.loc[flag] = df[(asset+'c1', 'a1505')].loc[flag]\n",
    "            elif traded_price in ['n_twap']:\n",
    "                flag = ts_px.isna()\n",
    "                ts_px.loc[flag] = df[(asset+'c1', 'd_twap')].loc[flag]        \n",
    "                \n",
    "        df_pxchg[asset] = ts_px.dropna().pct_change()[:insample]        \n",
    "vol_df = df_pxchg.rolling(vol_win).std()\n",
    "vol_df2 = pd.DataFrame(index=df.index)\n",
    "for asset in df_pxchg.columns:\n",
    "    vol_df2[asset] = robust_vol_calc(df_pxchg[asset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79a771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff='2010-01-01'\n",
    "shift_holdings = 1\n",
    "signal_cap = [-2, 2]\n",
    "chg_func = 'diff'\n",
    "bullish = False\n",
    "vol_win = 52\n",
    "\n",
    "by_asset = True\n",
    "\n",
    "signal_func = 'hlratio'\n",
    "param_rng = [480, 520, 2]\n",
    "#feature = \"sm_margin_north\"\n",
    "#feature = \"sf_neimeng_margin\"\n",
    "#feature = \"cnh_cny_spd2\"\n",
    "#feature = 'base_sw_csi500_ret'\n",
    "#feature = 'glass_sw_csi500_ret'\n",
    "#feature = 'sf_neimeng_cost'\n",
    "#feature = 'mn_44_gabon_tj'\n",
    "#feature = \"phycarry\"\n",
    "# feature = 'rebar_sales_inv_ratio'\n",
    "#feature = \"pmi_cn_cons_bus_exp\"\n",
    "# feature = 'au_td_sge'\n",
    "#feature='cnh_cny_spd2'\n",
    "#feature='etf_holdings'\n",
    "#feature='mn_44_gabon_tj'\n",
    "#feature = 'fxbasket_cumret'\n",
    "#feature=\"auag_etf_holdings_ratio\"\n",
    "#featrue = \"pmi_order_rminv_ratio\"\n",
    "#feature = \"auag_cme_warrant_ratio\"\n",
    "#feature = \"shibor_1m\" #\n",
    "feature='exch_warrant'\n",
    "\n",
    "freq=''\n",
    "\n",
    "signal_df = pd.DataFrame(index=df_pxchg.index)\n",
    "\n",
    "for asset in empiric_assets:\n",
    "    #feature_ts = df_pxchg[asset].cumsum()\n",
    "    #feature_ts = df[(asset+'c1', 'close')].dropna() #.pct_change() \n",
    "    if by_asset:\n",
    "        asset_feature = f\"{asset}_{feature}\"\n",
    "    else:\n",
    "        asset_feature = feature\n",
    "    feature_ts =spot_df[asset_feature].dropna() #.rolling(100).sum()\n",
    "    #feature_ts = feature_ts.diff(252)\n",
    "    #feature_ts = feature_ts.rolling(12).sum()\n",
    "    #feature_ts.index = feature_ts.index + pd.DateOffset(days=9) + chn_bday * 1\n",
    "    #feature_ts = np.log(feature_ts)\n",
    "    #feature_ts = feature_ts.rolling(100).sum()\n",
    "    #feature_ts = (1+stock_pct_chg[[\"SPY.P\"]].mean(axis=1)).cumprod()\n",
    "    #feature_ts = (1+stock_pct_chg[['SPY.P']].mean(axis=1)).cumprod()\n",
    "    #feature_ts = spot_df[asset_feature].ffill().reindex(index=df_pxchg.index)\n",
    "    #feature_ts = beta_ret_dict[asset].dropna().cumsum()\n",
    "    #feature_ts = spot_df[feature].ffill().reindex(index=pd.date_range(start=df.index[0], end=df.index[-1], freq=freq)).ffill().dropna()    \n",
    "    #feature_ts = df[(asset, 'c1', 'close')].dropna()\n",
    "    #ticker, param_rng = feature_map[asset]    \n",
    "    #feature_ts = (spot_df[beta_feature_map[asset][0]]/spot_df[beta_feature_map[asset][1]]).dropna()\n",
    "    #signal_ts = (feature_ts.ewm(8).mean() - feature_ts.ewm(30).mean())/feature_ts.diff().ewm(30).std()\n",
    "    # feature_ts = beta_residual(\n",
    "    #     spot_df[feature].dropna(),\n",
    "    #     df_pxchg[asset].dropna().cumsum(),\n",
    "    #     beta_win=120, \n",
    "    #     chg_func='diff', corr_step=1) \n",
    "#     feature_ts = beta_residual(\n",
    "#         spot_df[beta_feature_map[asset][0]].dropna(),\n",
    "#         spot_df[beta_feature_map[asset][1]].dropna(),\n",
    "#         beta_win=250, \n",
    "#         chg_func='pct_change') \n",
    "    #feature_ts = np.log(feature_ts)\n",
    "#     if asset in ['cu', 'al']:\n",
    "#         #param_rng = [1, 2, 1]\n",
    "#         feature_ts = feature_ts.rolling(20).mean()\n",
    "#     else:\n",
    "#         #param_rng = [1, 2, 1]\n",
    "#         feature_ts = feature_ts.rolling(2).mean()\n",
    "    feature_ts = feature_ts.reindex(index=cdates).ffill().reindex(index=bdates)\n",
    "    #feature_ts = feature_ts.ewm(1).mean()\n",
    "    #feature_ts = yoy_generic(feature_ts, label_func=calendar_label, group_col='label_day', func=chg_func)[asset_feature]    \n",
    "    #feature_ts = yoy_generic(feature_ts, label_func=lunar_label, group_col='label_day', func=chg_func)[asset_feature]    \n",
    "    signal_ts = calc_conv_signal(feature_ts, signal_func=signal_func, param_rng=param_rng, signal_cap=signal_cap, vol_win=vol_win) \n",
    "    #signal_ts = feature_ts\n",
    "    #signal_ts = 2*signal_ts - 1*signal_ts.shift(1)\n",
    "    #signal_ts = np.sign(signal_ts)    \n",
    "    #signal_ts = conv_ewm(feature_ts, [2, 6, 2], [8, 32, 4], vol_win=60)    \n",
    "    #signal_ts = zscore_roll(feature_ts, 120)\n",
    "    #signal_ts = ewmac(feature_ts, 8, 16, vol_win=0)\n",
    "    #signal_ts = pd.Series(1, index=df_pxchg.index)\n",
    "    #signal_ts.loc[signal_ts.index.month.isin([1, 2, 3, 4, 5, 6, 7, 12])] = 1\n",
    "    #signal_ts.loc[signal_ts.index.day.isin(range(16, 32))] += 1\n",
    "    #signal_ts = zscore_roll(feature_ts, 60)\n",
    "    #signal_ts = signal_hysteresis(signal_ts, 1.2, 0.6, False)\n",
    "    #signal_ts = seasonal_score(feature_ts.to_frame(), backward=10, forward=10, rolling_years=5, min_obs=10)\n",
    "    # signal_ts = seasonal_score(feature_ts.to_frame(), backward=15, forward=15, rolling_years=3, min_obs=30)\n",
    "    #signal_ts = create_holiday_window_series(df.index, opt_expiries, 1, 3) # - create_holiday_window_series(df.index, opt_expiries, 3, 4)\n",
    "    if not bullish:\n",
    "        signal_ts = -signal_ts    \n",
    "    \n",
    "    signal_ts = signal_ts.reindex(index=cdates).ffill().reindex(index=df_pxchg.index)\n",
    "    #signal_ts = signal_ts.rolling(2).mean()\n",
    "    #signal_ts = signal_ts.ewm(3).mean()\n",
    "    #signal_ts = signal_ts.shift(1)    \n",
    "    #signal_ts.loc[signal_ts.index.month.isin([1, 2])] = 0\n",
    "    #signal_ts = signal_hump(signal_ts, 0.2)\n",
    "    if '-' in asset:\n",
    "        sub_assets = asset.split('-')\n",
    "        if sub_assets[0] in signal_df.columns:\n",
    "            signal_df[sub_assets[0]] += signal_ts\n",
    "        else:\n",
    "            signal_df[sub_assets[0]] = signal_ts\n",
    "        if sub_assets[1] in signal_df.columns:\n",
    "            signal_df[sub_assets[1]] -= signal_ts\n",
    "        else:\n",
    "            signal_df[sub_assets[1]] = -signal_ts            \n",
    "    else:\n",
    "        signal_df[asset] = signal_ts\n",
    "\n",
    "#signal_df = xs_demean(signal_df)\n",
    "signal_df = signal_df + xs_demean(signal_df)\n",
    "#signal_df = signal_buffer(signal_df, 0.05)\n",
    "\n",
    "holding = generate_holding_from_signal(signal_df, vol_df, risk_scaling=1.0, asset_scaling=False)\n",
    "\n",
    "bt_metrics = MetricsBase(holdings=holding[signal_df.columns][cutoff:],\n",
    "                         returns=df_pxchg[signal_df.columns][cutoff:], \n",
    "                         shift_holdings=shift_holdings)\n",
    "trading_cost = dict([(asset, 0.6e-4) if asset in [\"T\", \"TF\"] else (asset, 2e-4) for asset in holding.columns])\n",
    "\n",
    "bt_metrics_w_cost = MetricsBase(holdings=holding[signal_df.columns][cutoff:],\n",
    "                                returns=df_pxchg[signal_df.columns][cutoff:], \n",
    "                                shift_holdings=shift_holdings,\n",
    "                                cost_dict=trading_cost)\n",
    "\n",
    "pnl_stats = bt_metrics.calculate_pnl_stats(shift=0, use_log_returns=False, tenors=pnl_tenors)\n",
    "pnl_stats_w_cost = bt_metrics_w_cost.calculate_pnl_stats(shift=0, use_log_returns=False, tenors=pnl_tenors)\n",
    "\n",
    "print(\"SR after cost:\\n\", pnl_stats_w_cost['sharpe'])\n",
    "print(pnl_stats_w_cost['asset_sharpe_stats'])\n",
    "print(\"Turnover: \\n%s\\nPNL per trade:\\n%s\\n\" % (pnl_stats_w_cost['turnover'], pnl_stats_w_cost['pnl_per_trade']))\n",
    "\n",
    "print(\"SR before cost:\\n\", pnl_stats['sharpe'])\n",
    "print(pnl_stats['asset_sharpe_stats'])\n",
    "print(\"Turnover: \\n%s\\nPNL per trade:\\n%s\\n\" % (pnl_stats['turnover'], pnl_stats['pnl_per_trade']))\n",
    "\n",
    "iplot(pnl_stats_w_cost['portfolio_cumpnl'], title='portfolio pnl with cost')\n",
    "iplot(pnl_stats_w_cost['asset_cumpnl'], title='asset pnl with cost')\n",
    "\n",
    "iplot(pnl_stats['portfolio_cumpnl'], title='portfolio pnl wo cost')\n",
    "iplot(pnl_stats['asset_cumpnl'], title='asset pnl wo cost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_setup = {\n",
    "    \"exch_wnt_hlr\": [\n",
    "        ['rb', 'hc', \"ru\", 'si', 'lc', 'ao', 'UR', 'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF'],\n",
    "        [\"exch_warrant\", \"hlratio\", [230, 250, 2], \"\", \"\", False, \"\", \"\", 240, [-2,2]]],\n",
    "    \"exch_wnt_hlr_xdemean\": [\n",
    "        ['rb', 'hc', \"ru\", 'si', 'lc', 'ao', 'UR', 'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF'],\n",
    "        [\"exch_warrant\", \"hlratio\", [230, 250, 2], \"\", \"\", False, \"\", \"\", 240, [-2,2]]],    \n",
    "    \"exch_wnt_hlr_mt\": [\n",
    "        ['rb', 'hc', \"ru\", 'si', 'lc', 'ao', 'UR', 'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF'],\n",
    "        [\"exch_warrant\", \"hlratio\", [80, 120, 2], \"\", \"\", False, \"\", \"ema3\", 240, [-2,2]]],\n",
    "    \"exch_wnt_hlr_mt_xdemean\": [\n",
    "        ['rb', 'hc', \"ru\", 'si', 'lc', 'ao', 'UR', 'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF'],\n",
    "        [\"exch_warrant\", \"hlratio\", [80, 120, 2], \"\", \"\", False, \"\", \"ema3\", 240, [-2,2]]],\n",
    "    \"exch_wnt_yoy_hlr\": [\n",
    "        ['rb', 'hc', \"ru\", 'si', 'lc', 'ao', 'UR', 'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF'],\n",
    "        [\"exch_warrant\", \"hlratio\", [230, 250, 2], 'cal_yoy_day', \"diff\", False, \"\", \"ema3\", 240, [-2,2]]],\n",
    "    \"exch_wnt_yoy_hlr_xdemean\": [\n",
    "        ['rb', 'hc', \"ru\", 'si', 'lc', 'ao', 'UR', 'ss', 'SA', 'FG', 'l', 'pp', 'v', 'TA', 'MA', 'eg', 'bu', 'fu', 'a', 'c', 'CF'],\n",
    "        [\"exch_warrant\", \"hlratio\", [230, 250, 2], 'cal_yoy_day', \"diff\", False, \"\", \"ema3\", 240, [-2,2]]],    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a334ff-3ed0-4690-a387-1f48de6ca4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff='2010-01-01'\n",
    "misc_fact = 14000\n",
    "feature_names = [\n",
    "    [\"exch_wnt_hlr\", 0.48*misc_fact],\n",
    "    [\"exch_wnt_hlr_xdemean\", 0.36*misc_fact],\n",
    "    #[\"exch_wnt_hlr_mt\", 1],\n",
    "    #[\"exch_wnt_hlr_mt_xdemean\", 1],    \n",
    "    [\"exch_wnt_yoy_hlr\", 0.12*misc_fact],\n",
    "    [\"exch_wnt_yoy_hlr_xdemean\", 0.24*misc_fact], \n",
    "]\n",
    "\n",
    "signal_dict = {}\n",
    "signal_df = pd.DataFrame(0, columns=empiric_assets, index=cdates)\n",
    "\n",
    "for feature_name, weight in feature_names:\n",
    "    signal_assets = feature_setup[feature_name][0]\n",
    "    feature, signal_func, param_rng, proc_func, chg_func, bullish, freq, post_func, vol_win, signal_cap = feature_setup[feature_name][1] \n",
    "    if feature in ['sinv', 'base_phybas', 'prem_bonded_warrant', 'prem_bonded_cif', \n",
    "                   'tc', 'phycarry', 'ryield', 'basmom5', 'basmom10', 'basmom20', 'basmom40', 'basmom60', 'basmom120', \n",
    "                   'base_inv', 'inv_shfe_d', 'inv_lme_total', 'inv_exch_d', 'px', 'etf_holdings', 'exch_warrant', 'smsf_prodcost']:\n",
    "        sig_df = pd.DataFrame(0, columns=empiric_assets, index=cdates)\n",
    "        for asset in empiric_assets:\n",
    "            if feature == 'base_inv':\n",
    "                asset_feature = base_inv.get(asset, f\"{asset}_{feature}\")\n",
    "            else:\n",
    "                asset_feature = f\"{asset}_{feature}\"\n",
    "            if (asset not in signal_assets) or (asset_feature not in spot_df.columns):\n",
    "                sig_df[asset] = np.nan\n",
    "                continue\n",
    "            if feature in ['base_phybas']:\n",
    "                if asset in ['cu', 'al']: \n",
    "                    proc_func = 'sma20'\n",
    "                else:\n",
    "                    proc_func = 'sma2'\n",
    "            signal_ts = calc_funda_signal(spot_df, asset_feature, signal_func, param_rng,\n",
    "                                          proc_func=proc_func, chg_func=chg_func, bullish=bullish,\n",
    "                                          freq=freq, signal_cap=signal_cap, bdates=bdates,\n",
    "                                          post_func=post_func, vol_win=vol_win)\n",
    "            sig_df[asset] = signal_ts\n",
    "        sig_df = sig_df.reindex(index=cdates).ffill().reindex(index=df_pxchg.index)\n",
    "        if \"xdemean\" in feature_name:\n",
    "            sig_df = xs_demean(sig_df)\n",
    "        elif \"xscore\" in feature_name:\n",
    "            sig_df = xs_score(sig_df)\n",
    "        elif \"xrank\" in feature_name:\n",
    "            sig_df = xs_rank(sig_df, 0.2)\n",
    "\n",
    "    else:\n",
    "        sig_ts = calc_funda_signal(spot_df, feature, signal_func, param_rng,\n",
    "                                   proc_func=proc_func, chg_func=chg_func, bullish=bullish,\n",
    "                                   freq=freq, signal_cap=signal_cap, bdates=bdates,\n",
    "                                   post_func=post_func, vol_win=vol_win)\n",
    "        sig_df = pd.DataFrame(0, columns=empiric_assets, index=cdates)\n",
    "        for asset in signal_assets:\n",
    "            if '-' in asset:\n",
    "                sub_assets = asset.split('-')\n",
    "                if sub_assets[0] in sig_df.columns:\n",
    "                    sig_df[sub_assets[0]] += sig_ts\n",
    "                else:\n",
    "                    sig_df[sub_assets[0]] = sig_ts\n",
    "                if sub_assets[1] in sig_df.columns:\n",
    "                    sig_df[sub_assets[1]] -= sig_ts\n",
    "                else:\n",
    "                    sig_df[sub_assets[1]] = -sig_ts            \n",
    "            else:\n",
    "                sig_df[asset] = sig_ts\n",
    "        sig_df = sig_df.reindex(index=cdates).ffill().reindex(index=df_pxchg.index)\n",
    "    last_func = post_func.split('|')[-1]\n",
    "    if 'buf' in last_func:\n",
    "        buffer_size = float(last_func[3:])\n",
    "        sig_df = signal_buffer(sig_df, buffer_size)\n",
    "    elif 'bfc' in last_func:\n",
    "        buffer_size = float(last_func[3:])\n",
    "        sig_df = signal_cost_optim(sig_df, \n",
    "                                   buffer_size, \n",
    "                                   vol_df, \n",
    "                                   cost_dict = dict([(asset, 1e-4) for asset in empiric_assets]))\n",
    "    sig_df = sig_df.reindex(index=cdates).ffill().reindex(index=df_pxchg.index).fillna(0)\n",
    "    signal_dict[feature_name] = sig_df\n",
    "    signal_df = signal_df + signal_dict[feature_name] * weight\n",
    "    \n",
    "signal_dict['combo'] = signal_df.dropna().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01292104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c36ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_df = pd.DataFrame(index=df_pxchg.index)\n",
    "for signal_name in signal_dict:\n",
    "    signal_df = signal_dict[signal_name]\n",
    "    holding = generate_holding_from_signal(signal_df, vol_df, risk_scaling=1, asset_scaling=False)    \n",
    "    \n",
    "    bt_metrics = MetricsBase(holdings=holding[empiric_assets][cutoff:],\n",
    "                             returns=df_pxchg[empiric_assets][cutoff:], \n",
    "                             shift_holdings=1)\n",
    "\n",
    "    bt_metrics_w_cost = MetricsBase(holdings=holding[empiric_assets][cutoff:],\n",
    "                                    returns=df_pxchg[empiric_assets][cutoff:], \n",
    "                                    shift_holdings=1,\n",
    "                                    cost_dict=simple_cost(holding.columns, trd_cost=1e-4))\n",
    "\n",
    "    pnl_stats = bt_metrics.calculate_pnl_stats(shift=0, use_log_returns=False, tenors=pnl_tenors)    \n",
    "    pnl_stats_w_cost = bt_metrics_w_cost.calculate_pnl_stats(shift=0, use_log_returns=False, tenors=pnl_tenors, perf_metrics=['sharpe', 'std', 'sortino', 'calmar'])    \n",
    "    perf_stats = transform_output(pnl_stats_w_cost)\n",
    "    pnl_df[signal_name] = pnl_stats_w_cost['portfolio_pnl']['total']\n",
    "    \n",
    "    print(\"signal=%s\\n\" % signal_name)\n",
    "    print(\"SR after cost:\\n\")\n",
    "    display(perf_stats)\n",
    "    print(pnl_stats_w_cost['asset_sharpe_stats'])\n",
    "    print(\"Turnover: \\n%s\\nPNL per trade:\\n%s\\n\" % (pnl_stats_w_cost['turnover'], pnl_stats_w_cost['pnl_per_trade']))\n",
    "\n",
    "    print(\"SR before cost:\\n\", pnl_stats['sharpe'])\n",
    "    print(pnl_stats['asset_sharpe_stats'])\n",
    "    print(\"Turnover: \\n%s\\nPNL per trade:\\n%s\\n\" % (pnl_stats['turnover'], pnl_stats['pnl_per_trade']))\n",
    "\n",
    "    iplot(pnl_stats_w_cost['portfolio_cumpnl'], title='portfolio pnl with cost')\n",
    "    iplot(pnl_stats_w_cost['asset_cumpnl'], title='asset pnl with cost')\n",
    "\n",
    "    iplot(pnl_stats['portfolio_cumpnl'], title='portfolio pnl wo cost')\n",
    "    iplot(pnl_stats['asset_cumpnl'], title='asset pnl wo cost')\n",
    "\n",
    "corr_cutoff = '2017-01-01'\n",
    "print(\"std:\\n%s\\n\" % pnl_df[corr_cutoff:].std(axis=0))\n",
    "\n",
    "pnl_w_df = pnl_df.drop(columns=['combo']).resample('W').sum()\n",
    "print(\"corr:\\n%s\\n\" % pnl_w_df[corr_cutoff:].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950ec7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypfopt\n",
    "from pypfopt import plotting\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "dpnl = pnl_df['2018-01-01':].drop(columns=['combo'])\n",
    "strat_std = dpnl.std()\n",
    "dpnl = dpnl/dpnl.std()\n",
    "\n",
    "max_sharpe = True\n",
    "\n",
    "if max_sharpe:\n",
    "    mu = expected_returns.mean_historical_return(dpnl, returns_data=True, frequency=244, compounding=False)\n",
    "else:\n",
    "    mu = None\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(dpnl, returns_data=True, frequency=244).ledoit_wolf()\n",
    "ef = EfficientFrontier(mu, S, weight_bounds= (0, 1)) \n",
    "\n",
    "fact_idx = {}\n",
    "for fact in dpnl.columns:\n",
    "    fact_idx[fact] = ef.tickers.index(fact)\n",
    "\n",
    "#ef.add_constraint(lambda w: w[fact_idx['ryield_ema_ts']] + w[fact_idx['ryield_ema_xdemean']] >= 0.3)\n",
    "#ef.add_constraint(lambda w: w[fact_idx['ryield_ema_ts']] + w[fact_idx['ryield_ema_xdemean']] <= 0.4)\n",
    "#ef.add_constraint(lambda w: w[fact_idx['ryield_ema_ts']] + w[fact_idx['ryield_ema_xdemean']] >= 0.3)\n",
    "# ef.add_constraint(lambda w: w[fact_idx['tsmom']] + w[fact_idx['macro2']] <= 0.24)\n",
    "\n",
    "#ef = EfficientFrontier(mu, S, weight_bounds=(0,1))\n",
    "if max_sharpe:\n",
    "    port_weights = ef.max_sharpe()\n",
    "else:\n",
    "    port_weights = ef.min_volatility()\n",
    "\n",
    "#port_weights = ef.clean_weights()\n",
    "port_weights = pd.Series(port_weights)\n",
    "print(\"port_weights=\\n%s\\n\" % port_weights)\n",
    "final_weights = port_weights.div(strat_std)\n",
    "print(\"final_weights=\\n%s\\n\" % final_weights)\n",
    "# mu = expected_returns.mean_historical_return(df)\n",
    "# S = risk_models.sample_cov(df)\n",
    "\n",
    "# # Optimize for maximal Sharpe ratio\n",
    "# ef = EfficientFrontier(mu, S)\n",
    "# weights = ef.max_sharpe()\n",
    "# ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a30dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10917f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_lag_config = {\n",
    "    'll_left': -20,\n",
    "    'll_right': 120,\n",
    "    'll_spacing': 5,\n",
    "    'll_sub_win': [(datetime.date(2008, 1, 1), datetime.date(2018, 12, 31)), \n",
    "                   (datetime.date(2019, 1, 1), datetime.date(2024, 12, 31)),],\n",
    "}\n",
    "\n",
    "ll_keys = ['fullsample'] + ['%s:%s' % (sd.strftime('%Y-%b-%d'), ed.strftime('%Y-%b-%d')) for sd, ed in lead_lag_config['ll_sub_win']]\n",
    "\n",
    "\n",
    "ll_left = lead_lag_config['ll_left']\n",
    "ll_right = lead_lag_config['ll_right']\n",
    "spacing = lead_lag_config['ll_spacing']\n",
    "\n",
    "leadlag_df = bt_metrics.lead_lag(ll_limit_left=ll_left, \n",
    "                                 ll_limit_right=ll_right,\n",
    "                                 ll_sub_windows=lead_lag_config['ll_sub_win'])\n",
    "\n",
    "fig, ax = plt.subplots(len(ll_keys), 1)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "for i, key in enumerate(ll_keys):\n",
    "    ts = leadlag_df['leadlag_sharpes'].loc[key]\n",
    "    ts.plot(kind='bar', ax = ax[i], title = f'lead_lag: {key}')\n",
    "    new_ticks = np.linspace(ll_left, ll_right, (ll_right-ll_left)//spacing+1)\n",
    "    ax[i].set_xticks(np.interp(new_ticks, ts.index, np.arange(ts.size)))\n",
    "    ax[i].set_xticklabels(new_ticks)\n",
    "    ax[i].axvline(x=-ll_left, color='red', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ls_pnl = bt_metrics.long_short_pnl()\n",
    "for key in ls_pnl:\n",
    "    ax.plot(ls_pnl[key]['portfolio_cumpnl'], '-', label=key)\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, bbox_to_anchor=(1.04, 1), loc='upper left')\n",
    "ax.grid()\n",
    "plt.title(\"long-short pnl\")\n",
    "plt.show()\n",
    "\n",
    "lagged = bt_metrics.lagged_pnl(lags=[1, 5, 10, 20, 30, 60, 75, 80])\n",
    "lagged['cumpnl'].plot()\n",
    "#print('lagged PNL\\n', lagged['sharpe'])\n",
    "plt.grid()\n",
    "plt.title('lagged pnl')\n",
    "plt.show()\n",
    "\n",
    "smoothed = bt_metrics.smoothed_pnl(smooth_hls=[1, 5, 10, 20, 30, 60, 75, 80])\n",
    "smoothed['cumpnl'].plot(figsize=(8, 6))\n",
    "#print('smoothed PNL\\n', smoothed['sharpe'])\n",
    "plt.grid()\n",
    "plt.title('smoothed pnl')\n",
    "plt.show()\n",
    "\n",
    "#tilt_timing = bt_metrics.tilt_timing(tilt_rolling_window=1*244) # default 3 years  tilt_rolling_window = 3 * 244 \n",
    "\n",
    "seasonal_pnl = bt_metrics.seasonal_pnl()\n",
    "cumpnl = seasonal_pnl['cumlog_pnl']\n",
    "cumpnl.set_index(cumpnl.index.astype('str')).plot(rot=30, figsize = (8, 6))\n",
    "#print('seasonal sharpe stats\\n', seasonal_pnl['sharpe_stats'])\n",
    "plt.grid()\n",
    "plt.title('monthly pnl')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "monthday_pnl = bt_metrics.monthday_pnl()\n",
    "cumpnl = monthday_pnl['cumlog_pnl']\n",
    "cumpnl.set_index(cumpnl.index.astype('str')).plot(rot=30, figsize = (8, 6))\n",
    "#print('monthday sharpe stats\\n', monthday_pnl['sharpe_stats'])\n",
    "plt.grid()\n",
    "plt.title('monthday pnl')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "week_pnl = bt_metrics.week_pnl()\n",
    "cumpnl = week_pnl['cumlog_pnl']\n",
    "cumpnl.set_index(cumpnl.index.astype('str')).plot(rot=30, figsize = (8, 6))\n",
    "#print('week sharpe stats\\n', week_pnl['sharpe_stats'])\n",
    "plt.grid()\n",
    "plt.title('weekday pnl')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "annual_pnl = bt_metrics.annual_pnl()\n",
    "cumpnl = annual_pnl['cumlog_pnl']\n",
    "cumpnl.set_index(cumpnl.index.astype('str')).plot(rot=30, figsize = (8, 6))\n",
    "#print('annual sharpe stats\\n', annual_pnl['sharpe_stats'])\n",
    "plt.grid()\n",
    "plt.title('annual pnl')\n",
    "plt.show()\n",
    "\n",
    "annual_pnl['cumlog_pnl'].mean(axis=1).plot()\n",
    "plt.grid()\n",
    "plt.title('annual averaged profile')\n",
    "plt.show()\n",
    "\n",
    "# turnover = bt_metrics.turnover()\n",
    "# print(turnover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb62fa-298d-4c56-9555-18e5d1bfe1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch feature exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4620a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "#     'margin_hrc_sh', \n",
    "    'strip_hsec',\n",
    "    'strip_3.0x685',\n",
    "    'pipe_1.5x3.25',    \n",
    "    'hrc_sh',\n",
    "    'crc_sh',\n",
    "    'billet_ts',\n",
    "    'macf_cfd',\n",
    "#     'gi_0.5_sh',\n",
    "#     'hsec_400x200',\n",
    "#     'highwire_6.5',\n",
    "#     'angle_50x5',\n",
    "#     'ibeam_25',\n",
    "#     'channel_16',\n",
    "\n",
    "#     'import_arb', 'pbf_prem', 'plt65_62',\n",
    "#     'io_laytime_45ports', 'io_inv_imp_31ports',\n",
    "#     'io_invdays_imp_mill(64)', 'io_inv_mill(64)', 'io_inv_imp_mill',\n",
    "#     'io_removal_port_41',\n",
    "#     'io_loading_14ports_ausbzl',\n",
    "]\n",
    "\n",
    "udf = spot_df[feature_list].dropna(how='all')\n",
    "# lunar_seasonal = True\n",
    "\n",
    "# if lunar_seasonal:\n",
    "#     seasonal_signal = tstool.lunar_label(udf)\n",
    "#     seasonal_signal = tstool.seasonal_group_score(\n",
    "#         seasonal_signal, score_cols=feature_list, yr_col='lunar_cny',\n",
    "#         group_col='lunar_wks', min_obs=3, backward=2, forward=2, rolling_years=3)\n",
    "#     seasonal_signal = seasonal_signal.reindex(index=df.index).ffill()\n",
    "\n",
    "for feature in udf.columns:\n",
    "    dataseries.plot_seasonal_df(udf[feature].dropna(), cutoff='2018-01-01', title=feature)\n",
    "    \n",
    "signal_raw = udf[feature_list].reindex(index=df.index).ffill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = '2012-01-01'\n",
    "signal_func = 'qtl'\n",
    "param_rng = [20, 42, 2]\n",
    "signal_cap = None # [-2, 2]\n",
    "product_list = ['rb', 'hc', 'i', 'j', 'jm', 'SF', 'FG', ] # 'v', 'cu', 'al', 'ss', 'UR', 'SA', 'ru'\n",
    "\n",
    "for asset in product_list:\n",
    "    if '_' in asset:\n",
    "        price_ts = (1 + beta_ret_dict[asset]).cumprod().to_frame('price')[cutoff:]\n",
    "    else:\n",
    "        price_ts = df[(asset, 'c1', 'close')].dropna().to_frame('price')[cutoff:]\n",
    "    pnl_list = [price_ts]\n",
    "    for feature in feature_list:\n",
    "        feature_ts = udf[feature].reindex(index=price_ts.index).ffill()\n",
    "        #feature_ts = feature_ts.pct_change(5)\n",
    "        #feature_ts = tstool.lunar_yoy(feature_ts, group_col='lunar_days', func='pct_change')\n",
    "        #feature_ts = tstool.seasonal_score(feature_ts.to_frame())\n",
    "        signal_ts = calc_conv_signal(feature_ts, signal_func=signal_func, param_rng=param_rng, signal_cap=signal_cap)\n",
    "        asset_df = pd.concat([price_ts, signal_ts], axis=1)\n",
    "        asset_df.columns = ['price', 'signal']\n",
    "        asset_df['signal'] = asset_df['signal'].apply(lambda x: x).ffill()\n",
    "        asset_df = asset_df.dropna(subset=['price'])\n",
    "        asset_df['position'] = (asset_df['signal']/asset_df['price'].pct_change().rolling(20).std()).shift(1).fillna(0)\n",
    "        asset_df['pnl'] = (asset_df['position'].shift(1) * asset_df['price'].pct_change()).fillna(0)\n",
    "        \n",
    "        sr = np.sqrt(244) * asset_df['pnl'].mean()/asset_df['pnl'].std()\n",
    "        pnl_per_trade = 100 * 100 * asset_df['pnl'].mean()/asset_df['position'].diff().abs().mean()\n",
    "        turnover = 100 * asset_df['position'].diff().abs().mean()/asset_df['position'].abs().mean()\n",
    "        print(f'{asset}:{feature} -> SR: {sr:.2f} -- PNL per trade: {pnl_per_trade:.2f} -- Turnover: {turnover:.2f}')\n",
    "        pnl_list.append(asset_df['pnl'].cumsum().to_frame(feature))\n",
    "    pnl_df = pd.concat(pnl_list, axis=1)\n",
    "    dataseries.plot_df_on_2ax(pnl_df, left_on=feature_list, right_on=['price'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01318eac-99af-4a7a-ba1a-b8c558ff253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal grid search run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab5495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_backward = False\n",
    "smooth_win = 1\n",
    "sig_smooth = tstool.exp_smooth(df_in, hl = smooth_win, fill_backward=fill_backward)\n",
    "\n",
    "demean = False\n",
    "mean_win = 244\n",
    "vol_win = 244\n",
    "if demean:\n",
    "    sig_scored = tstool.ts_score(sig_smooth, hl_mean=mean_win, min_obs_mean=mean_win, fill_backward_mean=fill_backward, \n",
    "                          hl_vol=vol_win, min_obs_vol=vol_win, fill_backward_vol=fill_backward)\n",
    "else:\n",
    "    sig_scored = tstool.ts_scale(sig_smooth, hl = vol_win, min_obs=vol_win, fill_backward=fill_backward)\n",
    "\n",
    "#sig_scored = tstool.xs_score(sig_smooth, demean=demean, hl=vol_win)\n",
    "\n",
    "signal_cap = 2.0\n",
    "\n",
    "score_capped = tstool.cap(sig_scored, -signal_cap, signal_cap)\n",
    "score_filled = tstool.filldown(score_capped, 2)\n",
    "score = tstool.lag(score_filled, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ad768",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_scale = 20\n",
    "asset_vol = tstool.exp_smooth(df_pxchg**2, hl=vol_scale, fill_backward=fill_backward)**0.5\n",
    "holding = score/asset_vol\n",
    "\n",
    "commod_list = holding.columns #['hc']\n",
    "btmetrics = MetricsBase(holdings = holding[commod_list], returns = df_pxchg[commod_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.623px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
